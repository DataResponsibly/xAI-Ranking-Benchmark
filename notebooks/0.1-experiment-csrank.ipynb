{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import pandas as pd\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from xai_ranking.benchmarks import (\n",
    "    human_in_the_loop,\n",
    "    hierarchical_ranking_explanation,\n",
    "    lime_experiment,\n",
    "    shap_experiment,\n",
    "    sharp_experiment,\n",
    "    participation_experiment,\n",
    ")\n",
    "from xai_ranking.preprocessing import (\n",
    "    preprocess_atp_data,\n",
    "    preprocess_csrank_data,\n",
    "    preprocess_higher_education_data,\n",
    ")\n",
    "from xai_ranking.datasets import (\n",
    "    fetch_atp_data,\n",
    "    fetch_csrank_data,\n",
    "    fetch_higher_education_data,\n",
    "    fetch_movers_data,\n",
    ")\n",
    "from xai_ranking.scorers import (\n",
    "    atp_score,\n",
    "    csrank_score,\n",
    "    higher_education_score,\n",
    ")\n",
    "\n",
    "RNG_SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The default value of regex will change from True to False in a future version. In addition, single character regular expressions will *not* be treated as literal strings when regex=True.\n"
     ]
    }
   ],
   "source": [
    "datasets = [\n",
    "    {\n",
    "        \"name\": \"CSRank\",\n",
    "        \"data\": fetch_csrank_data(),\n",
    "        \"preprocess\": preprocess_csrank_data,\n",
    "        \"scorer\": csrank_score,\n",
    "    },\n",
    "]\n",
    "xai_methods = [\n",
    "    {\"name\": \"LIME\", \"experiment\": lime_experiment},\n",
    "    {\"name\": \"SHAP\", \"experiment\": shap_experiment},\n",
    "    {\"name\": \"ShaRP\", \"experiment\": sharp_experiment},\n",
    "    # {\"name\": \"Participation\", \"experiment\": participation_experiment},\n",
    "    {\"name\": \"HRE\", \"experiment\": hierarchical_ranking_explanation},\n",
    "    {\"name\": \"HIL\", \"experiment\": human_in_the_loop},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = {}\n",
    "for dataset in datasets:\n",
    "    results[dataset[\"name\"]] = {}\n",
    "    for xai_method in xai_methods:\n",
    "        experiment_func = xai_method[\"experiment\"]\n",
    "        preprocess_func = dataset[\"preprocess\"]\n",
    "        score_func = dataset[\"scorer\"]\n",
    "        X, ranks, scores = preprocess_func(dataset[\"data\"])\n",
    "        contributions = experiment_func(X, score_func)\n",
    "        results[dataset[\"name\"]][xai_method[\"name\"]] = contributions\n",
    "        \n",
    "        result_df = pd.DataFrame(contributions, columns=X.columns, index=X.index)\n",
    "        result_df.to_csv(f\"results/_contributions_{dataset['name']}_{xai_method['name']}.csv\")\n",
    "        # with open(f\"_contributions_{dataset['name']}_{xai_method['name']}.npy\", \"wb\") as f:\n",
    "        #     np.save(f, contributions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ATP': {'LIME': array([[ 3.12376571,  2.00759403, -3.70052477,  1.22817005,  8.00124511,\n",
       "          -0.53089756],\n",
       "         [ 2.81473197, -0.28754179,  1.35617903,  2.53889913, -0.36674666,\n",
       "          -1.21787992],\n",
       "         [-0.78240949,  0.47546936,  3.86544551,  0.17699443, -0.02957212,\n",
       "           1.02093902],\n",
       "         [-3.60789384, -1.50606483,  0.69376593, -2.58814814, -5.3129342 ,\n",
       "           1.15970308],\n",
       "         [-3.54545993, -1.46871099, -3.70560436, -2.58181931, -5.19558699,\n",
       "           1.06457435]]),\n",
       "  'SHAP': array([[ 2.6 ,  1.6 , -1.32,  0.96,  6.42, -0.32],\n",
       "         [ 2.2 , -0.3 ,  1.08,  2.16, -0.08, -1.02],\n",
       "         [-0.6 ,  0.4 ,  2.98,  0.06, -0.08,  0.28],\n",
       "         [-2.4 , -0.9 ,  0.48, -0.24, -2.68,  0.78],\n",
       "         [-1.8 , -0.8 , -3.22, -2.94, -3.58,  0.28]]),\n",
       "  'ShaRP': array([[ 0.44666667,  0.43666667, -0.37      ,  0.14      ,  1.42666667,\n",
       "          -0.08      ],\n",
       "         [ 0.49666667, -0.08333333,  0.26666667,  0.64333333, -0.02666667,\n",
       "          -0.29666667],\n",
       "         [-0.26333333,  0.04666667,  0.48666667, -0.17      , -0.18666667,\n",
       "           0.08666667],\n",
       "         [-0.37333333, -0.24      ,  0.07333333, -0.15      , -0.54333333,\n",
       "           0.23333333],\n",
       "         [-0.30666667, -0.16      , -0.45666667, -0.46333333, -0.67      ,\n",
       "           0.05666667]]),\n",
       "  'HRE': array([[ 58.0799071 , 122.54826978,  95.99187409, 110.17867397,\n",
       "          105.017299  , -19.86969662],\n",
       "         [ 58.0799071 , 122.54826978,  95.99187409, 110.17867397,\n",
       "          105.017299  , -19.86969662],\n",
       "         [ 58.0799071 , 122.54826978,  95.99187409, 110.17867397,\n",
       "          105.017299  , -19.86969662],\n",
       "         [ 58.0799071 , 122.54826978,  95.99187409, 110.17867397,\n",
       "          105.017299  , -19.86969662],\n",
       "         [ 58.0799071 , 122.54826978,  95.99187409, 110.17867397,\n",
       "          105.017299  , -19.86969662]]),\n",
       "  'HIL': array([[0.026 , 0.016 , 0.0132, 0.0096, 0.0642, 0.0032],\n",
       "         [0.022 , 0.003 , 0.0108, 0.0216, 0.0008, 0.0102],\n",
       "         [0.006 , 0.004 , 0.0298, 0.0006, 0.0008, 0.0028],\n",
       "         [0.024 , 0.009 , 0.0048, 0.0024, 0.0268, 0.0078],\n",
       "         [0.018 , 0.008 , 0.0322, 0.0294, 0.0358, 0.0028]])}}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sharp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
