{
 "cells": [
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "!mkdir -p results\n",
    "!rm results/*"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "from lightgbm import LGBMRanker\n",
    "from sklearn.utils import check_random_state\n",
    "from xai_ranking.benchmarks import (\n",
    "    human_in_the_loop_experiment,\n",
    "    human_in_the_loop_batch_experiment,\n",
    "    hierarchical_ranking_explanation,\n",
    "    hierarchical_ranking_batch_explanation,\n",
    "    lime_experiment,\n",
    "    lime_batch_experiment,\n",
    "    shap_experiment,\n",
    "    shap_batch_experiment,\n",
    "    sharp_experiment,\n",
    "    sharp_batch_experiment,\n",
    "    # participation_experiment,\n",
    ")\n",
    "from xai_ranking.preprocessing import (\n",
    "    preprocess_atp_data,\n",
    "    preprocess_csrank_data,\n",
    "    preprocess_higher_education_data,\n",
    "    preprocess_movers_data,\n",
    ")\n",
    "from xai_ranking.datasets import (\n",
    "    fetch_atp_data,\n",
    "    fetch_csrank_data,\n",
    "    fetch_higher_education_data,\n",
    "    fetch_movers_data,\n",
    ")\n",
    "from xai_ranking.scorers import (\n",
    "    atp_score,\n",
    "    csrank_score,\n",
    "    higher_education_score,\n",
    ")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "RNG_SEED = 42"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "def check_random_states(random_state, n_runs):\n",
    "    random_state = check_random_state(random_state)\n",
    "    return (random_state.randint(0, 2 ** 32 - 1, dtype=\"uint32\") for _ in range(n_runs))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "# Set up ranker for the moving company dataset:\n",
    "X, ranks, score = preprocess_movers_data(fetch_movers_data(test=True))\n",
    "qids_train = X.index.value_counts().to_numpy()\n",
    "\n",
    "model = LGBMRanker(\n",
    "    objective=\"lambdarank\", label_gain=list(range(max(ranks) + 1)), verbose=-1\n",
    ")\n",
    "model.fit(\n",
    "    X=X,\n",
    "    y=ranks,\n",
    "    group=qids_train,\n",
    ")"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "datasets = [\n",
    "    {\n",
    "        \"name\": \"ATP\",\n",
    "        \"data\": fetch_atp_data(),\n",
    "        \"preprocess\": preprocess_atp_data,\n",
    "        \"scorer\": atp_score,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"CSRank\",\n",
    "        \"data\": fetch_csrank_data(),\n",
    "        \"preprocess\": preprocess_csrank_data,\n",
    "        \"scorer\": csrank_score,\n",
    "        \"done\": True\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Higher Education\",\n",
    "        \"data\": fetch_higher_education_data(year=2020),\n",
    "        \"preprocess\": preprocess_higher_education_data,\n",
    "        \"scorer\": higher_education_score,\n",
    "        \"done\": True\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Moving Company\",\n",
    "        \"data\": fetch_movers_data(test=True),\n",
    "        \"preprocess\": preprocess_movers_data,\n",
    "        \"scorer\": model.predict,\n",
    "        \"done\": True\n",
    "    },\n",
    "]\n",
    "xai_methods = [\n",
    "    {\"iterations\": 1, \"name\": \"LIME\", \"experiment\": lime_experiment},\n",
    "    {\"iterations\": 3, \"name\": \"BATCH_LIME\", \"experiment\": lime_batch_experiment},\n",
    "    {\"iterations\": 1, \"name\": \"SHAP\", \"experiment\": shap_experiment},\n",
    "    {\"iterations\": 3, \"name\": \"BATCH_SHAP\", \"experiment\": shap_batch_experiment},\n",
    "    {\"iterations\": 1, \"name\": \"ShaRP\",\n",
    "     \"experiment\": lambda *args, **kwargs: sharp_experiment(*args, **kwargs, verbose=True)},\n",
    "    {\"iterations\": 3, \"name\": \"BATCH_ShaRP\",\n",
    "     \"experiment\": lambda *args, **kwargs: sharp_batch_experiment(*args, **kwargs, verbose=True)},\n",
    "    # {\"iterations\": 1, \"name\": \"Participation\", \"experiment\": participation_experiment},\n",
    "    {\"iterations\": 1, \"name\": \"HRE\", \"experiment\": hierarchical_ranking_explanation},\n",
    "    {\"iterations\": 3, \"name\": \"BATCH_HRE\", \"experiment\": hierarchical_ranking_batch_explanation},\n",
    "    {\"iterations\": 1, \"name\": \"HIL\", \"experiment\": human_in_the_loop_experiment},\n",
    "    {\"iterations\": 3, \"name\": \"BATCH_HIL\", \"experiment\": human_in_the_loop_batch_experiment},\n",
    "]\n",
    "\n",
    "total_states = sum(map(lambda x: x[\"iterations\"], xai_methods)) * len(datasets)\n",
    "random_states = check_random_states(RNG_SEED, total_states)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "results = {}\n",
    "for dataset in datasets:\n",
    "    results[dataset[\"name\"]] = {}\n",
    "    for xai_method in xai_methods:\n",
    "        results[dataset[\"name\"]][xai_method[\"name\"]] = []\n",
    "\n",
    "        experiment_func = xai_method[\"experiment\"]\n",
    "        preprocess_func = dataset[\"preprocess\"]\n",
    "        score_func = dataset[\"scorer\"]\n",
    "\n",
    "        X, ranks, scores = preprocess_func(dataset[\"data\"])\n",
    "\n",
    "        for iteration_idx in range(xai_method[\"iterations\"]):\n",
    "            random_state = next(random_states)\n",
    "            if \"done\" in dataset and dataset[\"done\"]:\n",
    "                continue\n",
    "            contributions = experiment_func(X, score_func, random_state=random_state)\n",
    "\n",
    "            results[dataset[\"name\"]][xai_method[\"name\"]].append(contributions)\n",
    "\n",
    "            result_df = pd.DataFrame(contributions, columns=X.columns, index=X.index)\n",
    "            result_df.to_csv(f\"results/_contributions_{dataset['name']}_{xai_method['name']}_{iteration_idx}.csv\")\n",
    "        # with open(f\"_contributions_{dataset['name']}_{xai_method['name']}.npy\", \"wb\") as f:\n",
    "        #     np.save(f, contributions)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "metadata": {},
   "source": [
    "results"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def read_results_from_files():\n",
    "    return_dict = {}\n",
    "    for cur_dataset in datasets:\n",
    "        return_dict[cur_dataset[\"name\"]] = {}\n",
    "        for cur_xai_method in xai_methods:\n",
    "            return_dict[cur_dataset[\"name\"]][cur_xai_method[\"name\"]] = []\n",
    "            for iteration in range(cur_xai_method[\"iterations\"]):\n",
    "                fname = (f\"partial-results/_contributions_\"\n",
    "                         f\"{cur_dataset['name']}_{cur_xai_method['name']}_\"\n",
    "                         f\"{iteration}.csv\")\n",
    "                if os.path.isfile(fname):\n",
    "                    (return_dict[cur_dataset[\"name\"]][cur_xai_method[\"name\"]]\n",
    "                     .append(pd.read_csv(fname, index_col=0)))\n",
    "    return return_dict"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "results = read_results_from_files()",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "methods = [\"LIME\", \"SHAP\", \"ShaRP\", \"HRE\", \"HIL\"]\n",
    "batch_summary = {}\n",
    "aggregated_summary = {}\n",
    "for dataset in results:\n",
    "    rows = []\n",
    "    for method in methods:\n",
    "        population_experiments = results[dataset][method]\n",
    "        batch_experiments = results[dataset][f\"BATCH_{method}\"]\n",
    "        for pop_idx, pop_exp in enumerate(population_experiments):\n",
    "            for batch_idx, batch_exp in enumerate(batch_experiments):\n",
    "                squared_diffs: pd.DataFrame = (batch_exp - pop_exp) ** 2\n",
    "\n",
    "                errors_mean = squared_diffs.mean(axis=0).to_frame().T\n",
    "                errors_mean[\"method\"] = method\n",
    "                errors_mean[\"pop_idx\"] = pop_idx\n",
    "                errors_mean[\"batch_idx\"] = batch_idx\n",
    "                errors_mean[\"statistic\"] = \"mean\"\n",
    "                rows.append(errors_mean)\n",
    "\n",
    "                errors_var = squared_diffs.var(axis=0).to_frame().T\n",
    "                errors_var[\"method\"] = method\n",
    "                errors_var[\"pop_idx\"] = pop_idx\n",
    "                errors_var[\"batch_idx\"] = batch_idx\n",
    "                errors_var[\"statistic\"] = \"var\"\n",
    "                rows.append(errors_var)\n",
    "    dataset_summary = pd.concat(rows)\n",
    "    batch_summary[dataset] = dataset_summary\n",
    "    aggregated_summary[dataset] = (dataset_summary.groupby([\"statistic\", \"method\"]).mean()\n",
    "                                   .drop([\"pop_idx\", \"batch_idx\"], axis=1))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "aggregated_summary[\"ATP\"]",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": [
    "def plot_dataset_aggregated_summary(dataset_data, gap=0.3):\n",
    "    n_cols = len(dataset_data.columns)\n",
    "    x = np.arange(n_cols).astype(np.float64)\n",
    "\n",
    "    methods = dataset_data.index.get_level_values(\"method\").unique()\n",
    "    bars = len(methods)\n",
    "    bar_width = (1 - gap) / bars\n",
    "    x -= (bars - 1) * bar_width / 2\n",
    "\n",
    "    for method in methods:\n",
    "        plt.errorbar(x, dataset_data.loc[\"mean\", method], yerr=np.sqrt(dataset_data.loc[\"var\", method]), marker=\"o\", label=method, linestyle=\"None\")\n",
    "        x += bar_width \n",
    "    plt.legend()\n",
    "    plt.xticks(np.arange(n_cols), dataset_data.columns, rotation=45)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {},
   "cell_type": "code",
   "source": "plot_dataset_aggregated_summary(aggregated_summary[\"ATP\"])",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
