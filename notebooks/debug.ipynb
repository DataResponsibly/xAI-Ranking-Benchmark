{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a92cd798-50c5-413d-ad52-aa93b62f74bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "from sklearn.utils import check_random_state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f4f6f583-e1a5-4a9a-ab91-eff1e7d65976",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RandomState(MT19937)\n"
     ]
    }
   ],
   "source": [
    "RNG_SEED = 42\n",
    "rng = check_random_state(RNG_SEED)\n",
    "print(rng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "37ff8506-7087-40a8-af92-97298c9b876e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0, 9.0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results1 = 10\n",
    "results2 = 9\n",
    "total1 = 0 # np.sum(np.abs(results1))\n",
    "total2 = 1 # np.sum(np.abs(results2))\n",
    "percent1 = results1 / total1 if total1 != 0 else 0\n",
    "percent2 = results2 / total2 if total2 != 0 else 0\n",
    "percent1, percent2\n",
    "# return euclidean(results1 / total1, results2 / total2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b2df7018-738f-41f7-8405-5320ee6967fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "index1 = range(0,190)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "862c72e4-bf18-486c-a73b-24ee72afa3e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs = list(itertools.combinations(index1, 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "58e14cda-f0d8-4d38-ae37-ffa2340a9965",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([17326,  9354, 15107,  1554, 11078,  6162,  7858,  6734,  1767,\n",
       "        8064,  2919,  2885,  8331, 13247,  9690, 14763,  6725,  3877,\n",
       "        3143,  3971,  4333, 14695, 11282,   971, 17211, 11725, 16467,\n",
       "       13293, 17930, 14092,   635, 17808,  5026, 15467,  5265,  9724,\n",
       "       17948,  8769, 10942,  6826, 10958, 17291,  5537, 10689,  3578,\n",
       "        3369, 17565,  5028, 10730, 16610, 10126,  5849, 16481, 13974,\n",
       "        6634,  5381,  2495,  3942, 13474, 16182, 10275,  6311,  1355,\n",
       "        7615,  7576,  5817,  7255,  9509, 11334,  1493,  2325, 11440,\n",
       "       11283,   290,  7337,  2189, 11980, 17067,  1087,  4634, 10057,\n",
       "       14757, 15969,  5098,  6286,  2334, 13497, 17114, 14393,  4807,\n",
       "        2351,  8797, 11257, 17283, 15773,  1020, 11535, 17515, 17623,\n",
       "        3073])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_samples = rng.choice(\n",
    "        len(pairs),\n",
    "        size=100,\n",
    "        replace=False,\n",
    "    )\n",
    "\n",
    "pair_samples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "205fe926-fff8-4121-bedd-baf2e9207acb",
   "metadata": {},
   "outputs": [],
   "source": [
    "pairs_sample = [pairs[i] for i in pair_samples]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "1d3be348-d7d8-4c13-aa48-61333bafd10f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# [(pair[0], pair[1]) if np.random.choice([0,1]) else (pair[1], pair[0]) for pair in pairs_sample]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "46a6d481-e903-4859-a1a5-409d8e660396",
   "metadata": {},
   "outputs": [],
   "source": [
    "sam_idx1 = [i[0] for i in pairs]\n",
    "sam_idx2 = [i[1] for i in pairs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf38569-1b1d-4505-9eb9-74fffafd3ac4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f33040f1-fd38-4c91-bcee-bc77d250fd1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------- Higher Education | pairwise | rank ----------------\n",
      "Exact computation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:03<00:00,  3.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished computing exact results\n",
      "Alternating parameter: coalition_size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter coalition_size, value 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.34s/it]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:01<00:04,  1.34s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########\n",
      "teaching         71.70\n",
      "research         71.70\n",
      "citations        94.80\n",
      "income            5.25\n",
      "international    30.85\n",
      "Name: 51, dtype: float64\n",
      "teaching         279.766667\n",
      "research         280.350000\n",
      "citations        349.850000\n",
      "income            20.183333\n",
      "international    127.850000\n",
      "Name: École Polytechnique, dtype: float64\n",
      "##########\n",
      "teaching          42.40\n",
      "research          42.40\n",
      "citations        120.25\n",
      "income             5.40\n",
      "international     26.25\n",
      "Name: 59, dtype: float64\n",
      "teaching         125.650000\n",
      "research         125.650000\n",
      "citations        328.150000\n",
      "income            16.566667\n",
      "international     77.983333\n",
      "Name: Johannes Kepler University of Linz, dtype: float64\n",
      "##########\n",
      "teaching        -12.30\n",
      "research         10.25\n",
      "citations       -43.00\n",
      "income            3.30\n",
      "international    -3.65\n",
      "Name: 60, dtype: float64\n",
      "teaching         -28.516667\n",
      "research          31.150000\n",
      "citations       -107.683333\n",
      "income             9.066667\n",
      "international    -10.016667\n",
      "Name: Indian Institute of Technology (Indian School of Mines) Dhanbad, dtype: float64\n",
      "##########\n",
      "teaching        -5.30\n",
      "research        -3.35\n",
      "citations        0.70\n",
      "income          -0.50\n",
      "international    2.55\n",
      "Name: 65, dtype: float64\n",
      "teaching        -14.000000\n",
      "research         -7.166667\n",
      "citations         0.916667\n",
      "income           -1.083333\n",
      "international     9.333333\n",
      "Name: Autonomous University of the State of Mexico, dtype: float64\n",
      "Stored results for coalition_size | 1\n",
      "Parameter coalition_size, value 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.28s/it]\u001b[A\n",
      " 50%|█████     | 2/4 [00:03<00:03,  1.90s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########\n",
      "teaching          68.300000\n",
      "research          68.300000\n",
      "citations        186.750000\n",
      "income             9.366667\n",
      "international     42.483333\n",
      "Name: 59, dtype: float64\n",
      "teaching         125.650000\n",
      "research         125.650000\n",
      "citations        328.150000\n",
      "income            16.566667\n",
      "international     77.983333\n",
      "Name: Johannes Kepler University of Linz, dtype: float64\n",
      "##########\n",
      "teaching        -17.766667\n",
      "research         16.650000\n",
      "citations       -64.333333\n",
      "income            4.966667\n",
      "international    -5.816667\n",
      "Name: 60, dtype: float64\n",
      "teaching         -28.516667\n",
      "research          31.150000\n",
      "citations       -107.683333\n",
      "income             9.066667\n",
      "international    -10.016667\n",
      "Name: Indian Institute of Technology (Indian School of Mines) Dhanbad, dtype: float64\n",
      "##########\n",
      "teaching        -8.000000\n",
      "research        -4.616667\n",
      "citations        0.766667\n",
      "income          -0.733333\n",
      "international    4.583333\n",
      "Name: 65, dtype: float64\n",
      "teaching        -14.000000\n",
      "research         -7.166667\n",
      "citations         0.916667\n",
      "income           -1.083333\n",
      "international     9.333333\n",
      "Name: Autonomous University of the State of Mexico, dtype: float64\n",
      "Stored results for coalition_size | 2\n",
      "Parameter coalition_size, value 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.36s/it]\u001b[A\n",
      " 75%|███████▌  | 3/4 [00:05<00:02,  2.11s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########\n",
      "teaching          96.050000\n",
      "research          96.050000\n",
      "citations        256.150000\n",
      "income            13.166667\n",
      "international     59.783333\n",
      "Name: 59, dtype: float64\n",
      "teaching         125.650000\n",
      "research         125.650000\n",
      "citations        328.150000\n",
      "income            16.566667\n",
      "international     77.983333\n",
      "Name: Johannes Kepler University of Linz, dtype: float64\n",
      "Stored results for coalition_size | 3\n",
      "Parameter coalition_size, value 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.29s/it]\u001b[A\n",
      "100%|██████████| 4/4 [00:08<00:00,  2.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########\n",
      "teaching         125.650000\n",
      "research         125.650000\n",
      "citations        328.150000\n",
      "income            16.566667\n",
      "international     77.983333\n",
      "Name: 59, dtype: float64\n",
      "teaching         125.650000\n",
      "research         125.650000\n",
      "citations        328.150000\n",
      "income            16.566667\n",
      "international     77.983333\n",
      "Name: Johannes Kepler University of Linz, dtype: float64\n",
      "Stored results for coalition_size | 4\n",
      "Alternating parameter: sample_size\n",
      "---------------- Higher Education | pairwise | rank_score ----------------\n",
      "Exact computation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.14s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished computing exact results\n",
      "Alternating parameter: coalition_size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/4 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter coalition_size, value 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.28s/it]\u001b[A\n",
      " 25%|██▌       | 1/4 [00:01<00:03,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########\n",
      "teaching         1.488\n",
      "research         1.488\n",
      "citations        3.936\n",
      "income           0.197\n",
      "international    0.957\n",
      "Name: 59, dtype: float64\n",
      "teaching         3.7200\n",
      "research         3.7200\n",
      "citations        9.8400\n",
      "income           0.4925\n",
      "international    2.3925\n",
      "Name: Johannes Kepler University of Linz, dtype: float64\n",
      "Stored results for coalition_size | 1\n",
      "Parameter coalition_size, value 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.36s/it]\u001b[A\n",
      " 50%|█████     | 2/4 [00:02<00:02,  1.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########\n",
      "teaching         2.2320\n",
      "research         2.2320\n",
      "citations        5.9040\n",
      "income           0.2955\n",
      "international    1.4355\n",
      "Name: 59, dtype: float64\n",
      "teaching         3.7200\n",
      "research         3.7200\n",
      "citations        9.8400\n",
      "income           0.4925\n",
      "international    2.3925\n",
      "Name: Johannes Kepler University of Linz, dtype: float64\n",
      "Stored results for coalition_size | 2\n",
      "Parameter coalition_size, value 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.28s/it]\u001b[A\n",
      " 75%|███████▌  | 3/4 [00:03<00:01,  1.30s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########\n",
      "teaching         2.976\n",
      "research         2.976\n",
      "citations        7.872\n",
      "income           0.394\n",
      "international    1.914\n",
      "Name: 59, dtype: float64\n",
      "teaching         3.7200\n",
      "research         3.7200\n",
      "citations        9.8400\n",
      "income           0.4925\n",
      "international    2.3925\n",
      "Name: Johannes Kepler University of Linz, dtype: float64\n",
      "Stored results for coalition_size | 3\n",
      "Parameter coalition_size, value 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.38s/it]\u001b[A\n",
      "100%|██████████| 4/4 [00:05<00:00,  1.32s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########\n",
      "teaching         3.7200\n",
      "research         3.7200\n",
      "citations        9.8400\n",
      "income           0.4925\n",
      "international    2.3925\n",
      "Name: 59, dtype: float64\n",
      "teaching         3.7200\n",
      "research         3.7200\n",
      "citations        9.8400\n",
      "income           0.4925\n",
      "international    2.3925\n",
      "Name: Johannes Kepler University of Linz, dtype: float64\n",
      "Stored results for coalition_size | 4\n",
      "Alternating parameter: sample_size\n",
      "            dataset  n_observations             approach       parameter  \\\n",
      "0  Higher Education             100             pairwise             NaN   \n",
      "1  Higher Education             100        pairwise_rank  coalition_size   \n",
      "2  Higher Education             100        pairwise_rank  coalition_size   \n",
      "3  Higher Education             100        pairwise_rank  coalition_size   \n",
      "4  Higher Education             100        pairwise_rank  coalition_size   \n",
      "5  Higher Education             100             pairwise             NaN   \n",
      "6  Higher Education             100  pairwise_rank_score  coalition_size   \n",
      "7  Higher Education             100  pairwise_rank_score  coalition_size   \n",
      "8  Higher Education             100  pairwise_rank_score  coalition_size   \n",
      "9  Higher Education             100  pairwise_rank_score  coalition_size   \n",
      "\n",
      "   parameter_value  avg_time    time_0  agreement_kendall_0  \\\n",
      "0              NaN  3.647580  3.647580                  NaN   \n",
      "1              1.0  1.122109  1.122109                0.996   \n",
      "2              2.0  2.077305  2.077305                1.000   \n",
      "3              3.0  2.150107  2.150107                1.000   \n",
      "4              4.0  2.077832  2.077832                1.000   \n",
      "5              NaN  1.132612  1.132612                  NaN   \n",
      "6              1.0  1.070354  1.070354                1.000   \n",
      "7              2.0  1.151656  1.151656                1.000   \n",
      "8              3.0  1.070837  1.070837                1.000   \n",
      "9              4.0  1.172678  1.172678                1.000   \n",
      "\n",
      "   agreement_jaccard2_0  agreement_euclidean_0  fidelity_0  \n",
      "0                   NaN                    NaN        1.00  \n",
      "1              0.986667               0.861453        0.98  \n",
      "2              0.986667               0.908436        1.00  \n",
      "3              1.000000               0.954470        1.00  \n",
      "4              1.000000               1.000000        1.00  \n",
      "5                   NaN                    NaN        1.00  \n",
      "6              1.000000               0.993833        1.00  \n",
      "7              1.000000               0.995889        1.00  \n",
      "8              1.000000               0.997944        1.00  \n",
      "9              1.000000               1.000000        1.00  \n",
      "---------------- ATP | pairwise | rank ----------------\n",
      "Exact computation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished computing exact results\n",
      "Alternating parameter: coalition_size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter coalition_size, value 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.08s/it]\u001b[A\n",
      " 20%|██        | 1/5 [00:01<00:04,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########\n",
      "serve__pct_1st_serve               0.466667\n",
      "serve__pct_1st_serve_points_won   -0.566667\n",
      "serve__pct_2nd_serve_points_won    0.200000\n",
      "serve__pct_service_games_won      -0.300000\n",
      "serve__avg_aces_match             -1.366667\n",
      "serve__avg_double_faultsmatch      0.766667\n",
      "Name: 0, dtype: float64\n",
      "serve__pct_1st_serve               1.550000\n",
      "serve__pct_1st_serve_points_won   -2.516667\n",
      "serve__pct_2nd_serve_points_won    0.883333\n",
      "serve__pct_service_games_won      -1.783333\n",
      "serve__avg_aces_match             -4.650000\n",
      "serve__avg_double_faultsmatch      2.516667\n",
      "Name: Albert Ramos-Vinolas, dtype: float64\n",
      "##########\n",
      "serve__pct_1st_serve              -0.333333\n",
      "serve__pct_1st_serve_points_won   -1.300000\n",
      "serve__pct_2nd_serve_points_won    1.933333\n",
      "serve__pct_service_games_won       0.433333\n",
      "serve__avg_aces_match             -1.300000\n",
      "serve__avg_double_faultsmatch     -0.033333\n",
      "Name: 15, dtype: float64\n",
      "serve__pct_1st_serve              -1.383333\n",
      "serve__pct_1st_serve_points_won   -4.066667\n",
      "serve__pct_2nd_serve_points_won    6.000000\n",
      "serve__pct_service_games_won       1.466667\n",
      "serve__avg_aces_match             -4.066667\n",
      "serve__avg_double_faultsmatch     -0.950000\n",
      "Name: Joao Sousa, dtype: float64\n",
      "##########\n",
      "serve__pct_1st_serve               1.200000\n",
      "serve__pct_1st_serve_points_won    1.233333\n",
      "serve__pct_2nd_serve_points_won   -1.200000\n",
      "serve__pct_service_games_won       1.466667\n",
      "serve__avg_aces_match              1.233333\n",
      "serve__avg_double_faultsmatch      0.800000\n",
      "Name: 45, dtype: float64\n",
      "serve__pct_1st_serve               3.200000\n",
      "serve__pct_1st_serve_points_won    3.333333\n",
      "serve__pct_2nd_serve_points_won   -4.416667\n",
      "serve__pct_service_games_won       3.850000\n",
      "serve__avg_aces_match              3.333333\n",
      "serve__avg_double_faultsmatch      1.700000\n",
      "Name: Arthur Rinderknech, dtype: float64\n",
      "##########\n",
      "serve__pct_1st_serve              -1.266667\n",
      "serve__pct_1st_serve_points_won    0.400000\n",
      "serve__pct_2nd_serve_points_won   -1.266667\n",
      "serve__pct_service_games_won      -2.233333\n",
      "serve__avg_aces_match              0.200000\n",
      "serve__avg_double_faultsmatch     -0.566667\n",
      "Name: 60, dtype: float64\n",
      "serve__pct_1st_serve              -3.916667\n",
      "serve__pct_1st_serve_points_won    1.383333\n",
      "serve__pct_2nd_serve_points_won   -3.866667\n",
      "serve__pct_service_games_won      -6.866667\n",
      "serve__avg_aces_match              0.216667\n",
      "serve__avg_double_faultsmatch     -1.950000\n",
      "Name: Oscar Otte, dtype: float64\n",
      "##########\n",
      "serve__pct_1st_serve               0.233333\n",
      "serve__pct_1st_serve_points_won   -0.533333\n",
      "serve__pct_2nd_serve_points_won   -2.200000\n",
      "serve__pct_service_games_won      -0.700000\n",
      "serve__avg_aces_match              1.366667\n",
      "serve__avg_double_faultsmatch     -0.166667\n",
      "Name: 61, dtype: float64\n",
      "serve__pct_1st_serve               0.316667\n",
      "serve__pct_1st_serve_points_won   -1.966667\n",
      "serve__pct_2nd_serve_points_won   -7.333333\n",
      "serve__pct_service_games_won      -3.366667\n",
      "serve__avg_aces_match              3.316667\n",
      "serve__avg_double_faultsmatch     -0.966667\n",
      "Name: Ugo Humbert, dtype: float64\n",
      "##########\n",
      "serve__pct_1st_serve               1.600000\n",
      "serve__pct_1st_serve_points_won   -1.866667\n",
      "serve__pct_2nd_serve_points_won   -0.533333\n",
      "serve__pct_service_games_won      -1.966667\n",
      "serve__avg_aces_match             -0.500000\n",
      "serve__avg_double_faultsmatch      0.000000\n",
      "Name: 72, dtype: float64\n",
      "serve__pct_1st_serve               8.033333\n",
      "serve__pct_1st_serve_points_won   -5.633333\n",
      "serve__pct_2nd_serve_points_won   -2.300000\n",
      "serve__pct_service_games_won      -6.050000\n",
      "serve__avg_aces_match             -2.050000\n",
      "serve__avg_double_faultsmatch      0.000000\n",
      "Name: Federico Delbonis, dtype: float64\n",
      "##########\n",
      "serve__pct_1st_serve               0.000000\n",
      "serve__pct_1st_serve_points_won    1.266667\n",
      "serve__pct_2nd_serve_points_won   -0.066667\n",
      "serve__pct_service_games_won       1.266667\n",
      "serve__avg_aces_match              1.333333\n",
      "serve__avg_double_faultsmatch      0.000000\n",
      "Name: 73, dtype: float64\n",
      "serve__pct_1st_serve              -0.583333\n",
      "serve__pct_1st_serve_points_won    3.416667\n",
      "serve__pct_2nd_serve_points_won   -1.250000\n",
      "serve__pct_service_games_won       3.416667\n",
      "serve__avg_aces_match              4.583333\n",
      "serve__avg_double_faultsmatch     -0.583333\n",
      "Name: Matteo Berrettini, dtype: float64\n",
      "Stored results for coalition_size | 1\n",
      "Parameter coalition_size, value 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.08s/it]\u001b[A\n",
      " 40%|████      | 2/5 [00:02<00:03,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########\n",
      "serve__pct_1st_serve               0.616667\n",
      "serve__pct_1st_serve_points_won   -0.966667\n",
      "serve__pct_2nd_serve_points_won    0.283333\n",
      "serve__pct_service_games_won      -0.550000\n",
      "serve__avg_aces_match             -2.233333\n",
      "serve__avg_double_faultsmatch      1.100000\n",
      "Name: 0, dtype: float64\n",
      "serve__pct_1st_serve               1.550000\n",
      "serve__pct_1st_serve_points_won   -2.516667\n",
      "serve__pct_2nd_serve_points_won    0.883333\n",
      "serve__pct_service_games_won      -1.783333\n",
      "serve__avg_aces_match             -4.650000\n",
      "serve__avg_double_faultsmatch      2.516667\n",
      "Name: Albert Ramos-Vinolas, dtype: float64\n",
      "##########\n",
      "serve__pct_1st_serve              -1.866667\n",
      "serve__pct_1st_serve_points_won    0.583333\n",
      "serve__pct_2nd_serve_points_won   -1.866667\n",
      "serve__pct_service_games_won      -3.316667\n",
      "serve__avg_aces_match              0.200000\n",
      "serve__avg_double_faultsmatch     -0.833333\n",
      "Name: 60, dtype: float64\n",
      "serve__pct_1st_serve              -3.916667\n",
      "serve__pct_1st_serve_points_won    1.383333\n",
      "serve__pct_2nd_serve_points_won   -3.866667\n",
      "serve__pct_service_games_won      -6.866667\n",
      "serve__avg_aces_match              0.216667\n",
      "serve__avg_double_faultsmatch     -1.950000\n",
      "Name: Oscar Otte, dtype: float64\n",
      "##########\n",
      "serve__pct_1st_serve               0.266667\n",
      "serve__pct_1st_serve_points_won   -0.950000\n",
      "serve__pct_2nd_serve_points_won   -3.483333\n",
      "serve__pct_service_games_won      -1.400000\n",
      "serve__avg_aces_match              1.816667\n",
      "serve__avg_double_faultsmatch     -0.400000\n",
      "Name: 61, dtype: float64\n",
      "serve__pct_1st_serve               0.316667\n",
      "serve__pct_1st_serve_points_won   -1.966667\n",
      "serve__pct_2nd_serve_points_won   -7.333333\n",
      "serve__pct_service_games_won      -3.366667\n",
      "serve__avg_aces_match              3.316667\n",
      "serve__avg_double_faultsmatch     -0.966667\n",
      "Name: Ugo Humbert, dtype: float64\n",
      "##########\n",
      "serve__pct_1st_serve              -0.100000\n",
      "serve__pct_1st_serve_points_won    1.750000\n",
      "serve__pct_2nd_serve_points_won   -0.283333\n",
      "serve__pct_service_games_won       1.750000\n",
      "serve__avg_aces_match              1.983333\n",
      "serve__avg_double_faultsmatch     -0.100000\n",
      "Name: 73, dtype: float64\n",
      "serve__pct_1st_serve              -0.583333\n",
      "serve__pct_1st_serve_points_won    3.416667\n",
      "serve__pct_2nd_serve_points_won   -1.250000\n",
      "serve__pct_service_games_won       3.416667\n",
      "serve__avg_aces_match              4.583333\n",
      "serve__avg_double_faultsmatch     -0.583333\n",
      "Name: Matteo Berrettini, dtype: float64\n",
      "Stored results for coalition_size | 2\n",
      "Parameter coalition_size, value 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.08s/it]\u001b[A\n",
      " 60%|██████    | 3/5 [00:03<00:02,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########\n",
      "serve__pct_1st_serve               0.816667\n",
      "serve__pct_1st_serve_points_won   -1.416667\n",
      "serve__pct_2nd_serve_points_won    0.416667\n",
      "serve__pct_service_games_won      -0.816667\n",
      "serve__avg_aces_match             -3.083333\n",
      "serve__avg_double_faultsmatch      1.483333\n",
      "Name: 0, dtype: float64\n",
      "serve__pct_1st_serve               1.550000\n",
      "serve__pct_1st_serve_points_won   -2.516667\n",
      "serve__pct_2nd_serve_points_won    0.883333\n",
      "serve__pct_service_games_won      -1.783333\n",
      "serve__avg_aces_match             -4.650000\n",
      "serve__avg_double_faultsmatch      2.516667\n",
      "Name: Albert Ramos-Vinolas, dtype: float64\n",
      "##########\n",
      "serve__pct_1st_serve               0.316667\n",
      "serve__pct_1st_serve_points_won   -1.300000\n",
      "serve__pct_2nd_serve_points_won   -4.733333\n",
      "serve__pct_service_games_won      -2.066667\n",
      "serve__avg_aces_match              2.316667\n",
      "serve__avg_double_faultsmatch     -0.600000\n",
      "Name: 61, dtype: float64\n",
      "serve__pct_1st_serve               0.316667\n",
      "serve__pct_1st_serve_points_won   -1.966667\n",
      "serve__pct_2nd_serve_points_won   -7.333333\n",
      "serve__pct_service_games_won      -3.366667\n",
      "serve__avg_aces_match              3.316667\n",
      "serve__avg_double_faultsmatch     -0.966667\n",
      "Name: Ugo Humbert, dtype: float64\n",
      "##########\n",
      "serve__pct_1st_serve              -0.150000\n",
      "serve__pct_1st_serve_points_won    2.316667\n",
      "serve__pct_2nd_serve_points_won   -0.483333\n",
      "serve__pct_service_games_won       2.316667\n",
      "serve__avg_aces_match              2.816667\n",
      "serve__avg_double_faultsmatch     -0.150000\n",
      "Name: 73, dtype: float64\n",
      "serve__pct_1st_serve              -0.583333\n",
      "serve__pct_1st_serve_points_won    3.416667\n",
      "serve__pct_2nd_serve_points_won   -1.250000\n",
      "serve__pct_service_games_won       3.416667\n",
      "serve__avg_aces_match              4.583333\n",
      "serve__avg_double_faultsmatch     -0.583333\n",
      "Name: Matteo Berrettini, dtype: float64\n",
      "Stored results for coalition_size | 3\n",
      "Parameter coalition_size, value 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.08s/it]\u001b[A\n",
      " 80%|████████  | 4/5 [00:04<00:01,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########\n",
      "serve__pct_1st_serve               0.316667\n",
      "serve__pct_1st_serve_points_won   -1.633333\n",
      "serve__pct_2nd_serve_points_won   -6.000000\n",
      "serve__pct_service_games_won      -2.700000\n",
      "serve__avg_aces_match              2.816667\n",
      "serve__avg_double_faultsmatch     -0.800000\n",
      "Name: 61, dtype: float64\n",
      "serve__pct_1st_serve               0.316667\n",
      "serve__pct_1st_serve_points_won   -1.966667\n",
      "serve__pct_2nd_serve_points_won   -7.333333\n",
      "serve__pct_service_games_won      -3.366667\n",
      "serve__avg_aces_match              3.316667\n",
      "serve__avg_double_faultsmatch     -0.966667\n",
      "Name: Ugo Humbert, dtype: float64\n",
      "##########\n",
      "serve__pct_1st_serve              -0.250000\n",
      "serve__pct_1st_serve_points_won    2.916667\n",
      "serve__pct_2nd_serve_points_won   -0.750000\n",
      "serve__pct_service_games_won       2.916667\n",
      "serve__avg_aces_match              3.750000\n",
      "serve__avg_double_faultsmatch     -0.250000\n",
      "Name: 73, dtype: float64\n",
      "serve__pct_1st_serve              -0.583333\n",
      "serve__pct_1st_serve_points_won    3.416667\n",
      "serve__pct_2nd_serve_points_won   -1.250000\n",
      "serve__pct_service_games_won       3.416667\n",
      "serve__avg_aces_match              4.583333\n",
      "serve__avg_double_faultsmatch     -0.583333\n",
      "Name: Matteo Berrettini, dtype: float64\n",
      "Stored results for coalition_size | 4\n",
      "Parameter coalition_size, value 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.07s/it]\u001b[A\n",
      "100%|██████████| 5/5 [00:05<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########\n",
      "serve__pct_1st_serve              -0.583333\n",
      "serve__pct_1st_serve_points_won    3.416667\n",
      "serve__pct_2nd_serve_points_won   -1.250000\n",
      "serve__pct_service_games_won       3.416667\n",
      "serve__avg_aces_match              4.583333\n",
      "serve__avg_double_faultsmatch     -0.583333\n",
      "Name: 73, dtype: float64\n",
      "serve__pct_1st_serve              -0.583333\n",
      "serve__pct_1st_serve_points_won    3.416667\n",
      "serve__pct_2nd_serve_points_won   -1.250000\n",
      "serve__pct_service_games_won       3.416667\n",
      "serve__avg_aces_match              4.583333\n",
      "serve__avg_double_faultsmatch     -0.583333\n",
      "Name: Matteo Berrettini, dtype: float64\n",
      "Stored results for coalition_size | 5\n",
      "Alternating parameter: sample_size\n",
      "---------------- ATP | pairwise | rank_score ----------------\n",
      "Exact computation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:00<00:00,  1.12it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished computing exact results\n",
      "Alternating parameter: coalition_size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/5 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter coalition_size, value 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.07s/it]\u001b[A\n",
      " 20%|██        | 1/5 [00:01<00:04,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########\n",
      "serve__pct_1st_serve              -0.166667\n",
      "serve__pct_1st_serve_points_won    1.133333\n",
      "serve__pct_2nd_serve_points_won   -0.600000\n",
      "serve__pct_service_games_won       1.133333\n",
      "serve__avg_aces_match              1.666667\n",
      "serve__avg_double_faultsmatch     -0.166667\n",
      "Name: 73, dtype: float64\n",
      "serve__pct_1st_serve              -0.5\n",
      "serve__pct_1st_serve_points_won    3.4\n",
      "serve__pct_2nd_serve_points_won   -1.8\n",
      "serve__pct_service_games_won       3.4\n",
      "serve__avg_aces_match              5.0\n",
      "serve__avg_double_faultsmatch     -0.5\n",
      "Name: Matteo Berrettini, dtype: float64\n",
      "Stored results for coalition_size | 1\n",
      "Parameter coalition_size, value 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.07s/it]\u001b[A\n",
      " 40%|████      | 2/5 [00:02<00:03,  1.07s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########\n",
      "serve__pct_1st_serve              -0.25\n",
      "serve__pct_1st_serve_points_won    1.70\n",
      "serve__pct_2nd_serve_points_won   -0.90\n",
      "serve__pct_service_games_won       1.70\n",
      "serve__avg_aces_match              2.50\n",
      "serve__avg_double_faultsmatch     -0.25\n",
      "Name: 73, dtype: float64\n",
      "serve__pct_1st_serve              -0.5\n",
      "serve__pct_1st_serve_points_won    3.4\n",
      "serve__pct_2nd_serve_points_won   -1.8\n",
      "serve__pct_service_games_won       3.4\n",
      "serve__avg_aces_match              5.0\n",
      "serve__avg_double_faultsmatch     -0.5\n",
      "Name: Matteo Berrettini, dtype: float64\n",
      "Stored results for coalition_size | 2\n",
      "Parameter coalition_size, value 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.07s/it]\u001b[A\n",
      " 60%|██████    | 3/5 [00:03<00:02,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########\n",
      "serve__pct_1st_serve              -0.333333\n",
      "serve__pct_1st_serve_points_won    2.266667\n",
      "serve__pct_2nd_serve_points_won   -1.200000\n",
      "serve__pct_service_games_won       2.266667\n",
      "serve__avg_aces_match              3.333333\n",
      "serve__avg_double_faultsmatch     -0.333333\n",
      "Name: 73, dtype: float64\n",
      "serve__pct_1st_serve              -0.5\n",
      "serve__pct_1st_serve_points_won    3.4\n",
      "serve__pct_2nd_serve_points_won   -1.8\n",
      "serve__pct_service_games_won       3.4\n",
      "serve__avg_aces_match              5.0\n",
      "serve__avg_double_faultsmatch     -0.5\n",
      "Name: Matteo Berrettini, dtype: float64\n",
      "Stored results for coalition_size | 3\n",
      "Parameter coalition_size, value 4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.08s/it]\u001b[A\n",
      " 80%|████████  | 4/5 [00:04<00:01,  1.08s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########\n",
      "serve__pct_1st_serve              -0.416667\n",
      "serve__pct_1st_serve_points_won    2.833333\n",
      "serve__pct_2nd_serve_points_won   -1.500000\n",
      "serve__pct_service_games_won       2.833333\n",
      "serve__avg_aces_match              4.166667\n",
      "serve__avg_double_faultsmatch     -0.416667\n",
      "Name: 73, dtype: float64\n",
      "serve__pct_1st_serve              -0.5\n",
      "serve__pct_1st_serve_points_won    3.4\n",
      "serve__pct_2nd_serve_points_won   -1.8\n",
      "serve__pct_service_games_won       3.4\n",
      "serve__avg_aces_match              5.0\n",
      "serve__avg_double_faultsmatch     -0.5\n",
      "Name: Matteo Berrettini, dtype: float64\n",
      "Stored results for coalition_size | 4\n",
      "Parameter coalition_size, value 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.07s/it]\u001b[A\n",
      "100%|██████████| 5/5 [00:05<00:00,  1.08s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########\n",
      "serve__pct_1st_serve              -0.5\n",
      "serve__pct_1st_serve_points_won    3.4\n",
      "serve__pct_2nd_serve_points_won   -1.8\n",
      "serve__pct_service_games_won       3.4\n",
      "serve__avg_aces_match              5.0\n",
      "serve__avg_double_faultsmatch     -0.5\n",
      "Name: 73, dtype: float64\n",
      "serve__pct_1st_serve              -0.5\n",
      "serve__pct_1st_serve_points_won    3.4\n",
      "serve__pct_2nd_serve_points_won   -1.8\n",
      "serve__pct_service_games_won       3.4\n",
      "serve__avg_aces_match              5.0\n",
      "serve__avg_double_faultsmatch     -0.5\n",
      "Name: Matteo Berrettini, dtype: float64\n",
      "Stored results for coalition_size | 5\n",
      "Alternating parameter: sample_size\n",
      "   dataset  n_observations             approach       parameter  \\\n",
      "0      ATP              83             pairwise             NaN   \n",
      "1      ATP              83        pairwise_rank  coalition_size   \n",
      "2      ATP              83        pairwise_rank  coalition_size   \n",
      "3      ATP              83        pairwise_rank  coalition_size   \n",
      "4      ATP              83        pairwise_rank  coalition_size   \n",
      "5      ATP              83        pairwise_rank  coalition_size   \n",
      "6      ATP              83             pairwise             NaN   \n",
      "7      ATP              83  pairwise_rank_score  coalition_size   \n",
      "8      ATP              83  pairwise_rank_score  coalition_size   \n",
      "9      ATP              83  pairwise_rank_score  coalition_size   \n",
      "10     ATP              83  pairwise_rank_score  coalition_size   \n",
      "11     ATP              83  pairwise_rank_score  coalition_size   \n",
      "\n",
      "    parameter_value  avg_time    time_0  agreement_kendall_0  \\\n",
      "0               NaN  0.890399  0.890399                  NaN   \n",
      "1               1.0  0.889712  0.889712             0.963052   \n",
      "2               2.0  0.890029  0.890029             0.993574   \n",
      "3               3.0  0.890488  0.890488             1.000000   \n",
      "4               4.0  0.890913  0.890913             1.000000   \n",
      "5               5.0  0.890960  0.890960             1.000000   \n",
      "6               NaN  0.891074  0.891074                  NaN   \n",
      "7               1.0  0.890288  0.890288             0.998394   \n",
      "8               2.0  0.890702  0.890702             0.998394   \n",
      "9               3.0  0.891118  0.891118             0.998394   \n",
      "10              4.0  0.893817  0.893817             1.000000   \n",
      "11              5.0  0.891990  0.891990             1.000000   \n",
      "\n",
      "    agreement_jaccard2_0  agreement_euclidean_0  fidelity_0  \n",
      "0                    NaN                    NaN    1.000000  \n",
      "1               0.967871               0.841922    0.975904  \n",
      "2               0.983936               0.881120    0.975904  \n",
      "3               0.983936               0.920587    0.975904  \n",
      "4               0.991968               0.960076    0.987952  \n",
      "5               1.000000               1.000000    1.000000  \n",
      "6                    NaN                    NaN    1.000000  \n",
      "7               1.000000               0.908774    1.000000  \n",
      "8               1.000000               0.931580    1.000000  \n",
      "9               1.000000               0.954387    1.000000  \n",
      "10              1.000000               0.977193    1.000000  \n",
      "11              1.000000               1.000000    1.000000  \n",
      "---------------- CSRank | pairwise | rank ----------------\n",
      "Exact computation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.07s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished computing exact results\n",
      "Alternating parameter: coalition_size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter coalition_size, value 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.28s/it]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:01<00:02,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########\n",
      "Count AI                   1.083333\n",
      "Count Systems              1.500000\n",
      "Count Theory              -0.833333\n",
      "Count Interdisciplinary   -1.250000\n",
      "Name: 1, dtype: float64\n",
      "Count AI                   2.75\n",
      "Count Systems              3.25\n",
      "Count Theory              -1.75\n",
      "Count Interdisciplinary   -2.25\n",
      "Name: University of Southern California, dtype: float64\n",
      "##########\n",
      "Count AI                  -4.833333\n",
      "Count Systems             -7.666667\n",
      "Count Theory              -2.666667\n",
      "Count Interdisciplinary   -4.833333\n",
      "Name: 2, dtype: float64\n",
      "Count AI                   -7.833333\n",
      "Count Systems             -11.833333\n",
      "Count Theory               -3.500000\n",
      "Count Interdisciplinary    -7.833333\n",
      "Name: Arizona State University, dtype: float64\n",
      "##########\n",
      "Count AI                  -12.666667\n",
      "Count Systems              -2.666667\n",
      "Count Theory                6.250000\n",
      "Count Interdisciplinary    -5.583333\n",
      "Name: 10, dtype: float64\n",
      "Count AI                  -25.583333\n",
      "Count Systems              -5.250000\n",
      "Count Theory                9.250000\n",
      "Count Interdisciplinary   -10.416667\n",
      "Name: University of Missouri, dtype: float64\n",
      "##########\n",
      "Count AI                   11.50\n",
      "Count Systems              -5.50\n",
      "Count Theory                5.75\n",
      "Count Interdisciplinary     5.75\n",
      "Name: 16, dtype: float64\n",
      "Count AI                   24.666667\n",
      "Count Systems             -13.000000\n",
      "Count Theory               12.166667\n",
      "Count Interdisciplinary    12.166667\n",
      "Name: Boston College, dtype: float64\n",
      "##########\n",
      "Count AI                    6.500000\n",
      "Count Systems              10.000000\n",
      "Count Theory                2.666667\n",
      "Count Interdisciplinary     6.500000\n",
      "Name: 24, dtype: float64\n",
      "Count AI                   14.500000\n",
      "Count Systems              21.500000\n",
      "Count Theory                6.166667\n",
      "Count Interdisciplinary    14.833333\n",
      "Name: University of Pennsylvania, dtype: float64\n",
      "##########\n",
      "Count AI                  -6.666667\n",
      "Count Systems              5.666667\n",
      "Count Theory               5.666667\n",
      "Count Interdisciplinary    0.000000\n",
      "Name: 31, dtype: float64\n",
      "Count AI                  -15.333333\n",
      "Count Systems              10.666667\n",
      "Count Theory               10.666667\n",
      "Count Interdisciplinary     0.000000\n",
      "Name: University of Iowa, dtype: float64\n",
      "##########\n",
      "Count AI                  -31.250000\n",
      "Count Systems             -33.000000\n",
      "Count Theory               -7.666667\n",
      "Count Interdisciplinary   -31.250000\n",
      "Name: 57, dtype: float64\n",
      "Count AI                  -39.750000\n",
      "Count Systems             -42.916667\n",
      "Count Theory               -9.250000\n",
      "Count Interdisciplinary   -40.083333\n",
      "Name: Florida Institute of Technology, dtype: float64\n",
      "##########\n",
      "Count AI                  -1.333333\n",
      "Count Systems              5.833333\n",
      "Count Theory               3.000000\n",
      "Count Interdisciplinary    3.000000\n",
      "Name: 62, dtype: float64\n",
      "Count AI                   -3.250000\n",
      "Count Systems              12.416667\n",
      "Count Theory                7.416667\n",
      "Count Interdisciplinary     7.416667\n",
      "Name: Kent State University, dtype: float64\n",
      "##########\n",
      "Count AI                    9.583333\n",
      "Count Systems              13.250000\n",
      "Count Theory                4.416667\n",
      "Count Interdisciplinary     9.583333\n",
      "Name: 71, dtype: float64\n",
      "Count AI                   43.0\n",
      "Count Systems              51.0\n",
      "Count Theory               23.0\n",
      "Count Interdisciplinary    43.0\n",
      "Name: University of Washington, dtype: float64\n",
      "##########\n",
      "Count AI                  -3.416667\n",
      "Count Systems             -4.416667\n",
      "Count Theory              -1.083333\n",
      "Count Interdisciplinary   -3.416667\n",
      "Name: 80, dtype: float64\n",
      "Count AI                   -8.583333\n",
      "Count Systems             -10.250000\n",
      "Count Theory               -2.250000\n",
      "Count Interdisciplinary    -7.916667\n",
      "Name: University of Delaware, dtype: float64\n",
      "Stored results for coalition_size | 1\n",
      "Parameter coalition_size, value 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.27s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:02<00:01,  1.28s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########\n",
      "Count AI                  -6.083333\n",
      "Count Systems             -9.583333\n",
      "Count Theory              -3.000000\n",
      "Count Interdisciplinary   -6.083333\n",
      "Name: 2, dtype: float64\n",
      "Count AI                   -7.833333\n",
      "Count Systems             -11.833333\n",
      "Count Theory               -3.500000\n",
      "Count Interdisciplinary    -7.833333\n",
      "Name: Arizona State University, dtype: float64\n",
      "##########\n",
      "Count AI                  -10.583333\n",
      "Count Systems               8.416667\n",
      "Count Theory                8.416667\n",
      "Count Interdisciplinary     0.000000\n",
      "Name: 31, dtype: float64\n",
      "Count AI                  -15.333333\n",
      "Count Systems              10.666667\n",
      "Count Theory               10.666667\n",
      "Count Interdisciplinary     0.000000\n",
      "Name: University of Iowa, dtype: float64\n",
      "##########\n",
      "Count AI                  -1.750000\n",
      "Count Systems              8.916667\n",
      "Count Theory               4.916667\n",
      "Count Interdisciplinary    4.916667\n",
      "Name: 62, dtype: float64\n",
      "Count AI                   -3.250000\n",
      "Count Systems              12.416667\n",
      "Count Theory                7.416667\n",
      "Count Interdisciplinary     7.416667\n",
      "Name: Kent State University, dtype: float64\n",
      "##########\n",
      "Count AI                   18.25\n",
      "Count Systems              24.00\n",
      "Count Theory                7.50\n",
      "Count Interdisciplinary    18.25\n",
      "Name: 71, dtype: float64\n",
      "Count AI                   43.0\n",
      "Count Systems              51.0\n",
      "Count Theory               23.0\n",
      "Count Interdisciplinary    43.0\n",
      "Name: University of Washington, dtype: float64\n",
      "Stored results for coalition_size | 2\n",
      "Parameter coalition_size, value 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.27s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:03<00:00,  1.28s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########\n",
      "Count AI                   -7.833333\n",
      "Count Systems             -11.833333\n",
      "Count Theory               -3.500000\n",
      "Count Interdisciplinary    -7.833333\n",
      "Name: 2, dtype: float64\n",
      "Count AI                   -7.833333\n",
      "Count Systems             -11.833333\n",
      "Count Theory               -3.500000\n",
      "Count Interdisciplinary    -7.833333\n",
      "Name: Arizona State University, dtype: float64\n",
      "##########\n",
      "Count AI                  -15.333333\n",
      "Count Systems              10.666667\n",
      "Count Theory               10.666667\n",
      "Count Interdisciplinary     0.000000\n",
      "Name: 31, dtype: float64\n",
      "Count AI                  -15.333333\n",
      "Count Systems              10.666667\n",
      "Count Theory               10.666667\n",
      "Count Interdisciplinary     0.000000\n",
      "Name: University of Iowa, dtype: float64\n",
      "##########\n",
      "Count AI                   -3.250000\n",
      "Count Systems              12.416667\n",
      "Count Theory                7.416667\n",
      "Count Interdisciplinary     7.416667\n",
      "Name: 62, dtype: float64\n",
      "Count AI                   -3.250000\n",
      "Count Systems              12.416667\n",
      "Count Theory                7.416667\n",
      "Count Interdisciplinary     7.416667\n",
      "Name: Kent State University, dtype: float64\n",
      "##########\n",
      "Count AI                   43.0\n",
      "Count Systems              51.0\n",
      "Count Theory               23.0\n",
      "Count Interdisciplinary    43.0\n",
      "Name: 71, dtype: float64\n",
      "Count AI                   43.0\n",
      "Count Systems              51.0\n",
      "Count Theory               23.0\n",
      "Count Interdisciplinary    43.0\n",
      "Name: University of Washington, dtype: float64\n",
      "Stored results for coalition_size | 3\n",
      "Alternating parameter: sample_size\n",
      "---------------- CSRank | pairwise | rank_score ----------------\n",
      "Exact computation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.24s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished computing exact results\n",
      "Alternating parameter: coalition_size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/3 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter coalition_size, value 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.27s/it]\u001b[A\n",
      " 33%|███▎      | 1/3 [00:01<00:02,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##########\n",
      "Count AI                   0.056296\n",
      "Count Systems             -0.084601\n",
      "Count Theory               0.083728\n",
      "Count Interdisciplinary    0.192961\n",
      "Name: 76, dtype: float64\n",
      "Count AI                   0.108763\n",
      "Count Systems             -0.159675\n",
      "Count Theory               0.162534\n",
      "Count Interdisciplinary    0.382019\n",
      "Name: Univ. of California - Santa Cruz, dtype: float64\n",
      "Stored results for coalition_size | 1\n",
      "Parameter coalition_size, value 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.26s/it]\u001b[A\n",
      " 67%|██████▋   | 2/3 [00:02<00:01,  1.27s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored results for coalition_size | 2\n",
      "Parameter coalition_size, value 3\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:00<?, ?it/s]\u001b[A\n",
      "100%|██████████| 1/1 [00:01<00:00,  1.27s/it]\u001b[A\n",
      "100%|██████████| 3/3 [00:03<00:00,  1.27s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored results for coalition_size | 3\n",
      "Alternating parameter: sample_size\n",
      "  dataset  n_observations             approach       parameter  \\\n",
      "0  CSRank             100             pairwise             NaN   \n",
      "1  CSRank             100        pairwise_rank  coalition_size   \n",
      "2  CSRank             100        pairwise_rank  coalition_size   \n",
      "3  CSRank             100        pairwise_rank  coalition_size   \n",
      "4  CSRank             100             pairwise             NaN   \n",
      "5  CSRank             100  pairwise_rank_score  coalition_size   \n",
      "6  CSRank             100  pairwise_rank_score  coalition_size   \n",
      "7  CSRank             100  pairwise_rank_score  coalition_size   \n",
      "\n",
      "   parameter_value  avg_time    time_0  agreement_kendall_0  \\\n",
      "0              NaN  1.071583  1.071583                  NaN   \n",
      "1              1.0  1.070973  1.070973             0.988333   \n",
      "2              2.0  1.071334  1.071334             1.000000   \n",
      "3              3.0  1.071083  1.071083             1.000000   \n",
      "4              NaN  1.243025  1.243025                  NaN   \n",
      "5              1.0  1.070810  1.070810             1.000000   \n",
      "6              2.0  1.071476  1.071476             1.000000   \n",
      "7              3.0  1.071813  1.071813             1.000000   \n",
      "\n",
      "   agreement_jaccard2_0  agreement_euclidean_0  fidelity_0  \n",
      "0                   NaN                    NaN        1.00  \n",
      "1              0.980000               0.894608        0.99  \n",
      "2              1.000000               0.941788        0.99  \n",
      "3              1.000000               1.000000        1.00  \n",
      "4                   NaN                    NaN        1.00  \n",
      "5              0.993333               0.995582        1.00  \n",
      "6              1.000000               0.997657        1.00  \n",
      "7              1.000000               1.000000        1.00  \n",
      "---------------- Synthetic_0 | pairwise | rank ----------------\n",
      "Exact computation\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:01<00:00,  1.10s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished computing exact results\n",
      "Alternating parameter: coalition_size\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter coalition_size, value 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/1 [00:01<?, ?it/s]\u001b[A\n",
      "  0%|          | 0/2 [00:01<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[3], line 349\u001b[0m\n\u001b[1;32m    346\u001b[0m     sam_idx2 \u001b[38;5;241m=\u001b[39m [i[\u001b[38;5;241m1\u001b[39m] \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m pairs]\n\u001b[1;32m    347\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m idx1, idx2 \u001b[38;5;129;01min\u001b[39;00m pairs:\n\u001b[1;32m    348\u001b[0m         pairwise\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 349\u001b[0m             sharp\u001b[38;5;241m.\u001b[39mpairwise(X\u001b[38;5;241m.\u001b[39mvalues[idx1], X\u001b[38;5;241m.\u001b[39mvalues[idx2])\n\u001b[1;32m    350\u001b[0m         )\n\u001b[1;32m    351\u001b[0m     contr \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39marray(pairwise)\n\u001b[1;32m    353\u001b[0m end \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mtime()\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.12/site-packages/sharp/base.py:254\u001b[0m, in \u001b[0;36mShaRP.pairwise\u001b[0;34m(self, sample1, sample2, **kwargs)\u001b[0m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    252\u001b[0m     coalition_size \u001b[38;5;241m=\u001b[39m sample1\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m] \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[0;32m--> 254\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mindividual(\n\u001b[1;32m    255\u001b[0m     sample1,\n\u001b[1;32m    256\u001b[0m     X\u001b[38;5;241m=\u001b[39msample2,\n\u001b[1;32m    257\u001b[0m     sample_size\u001b[38;5;241m=\u001b[39msample_size,\n\u001b[1;32m    258\u001b[0m     coalition_size\u001b[38;5;241m=\u001b[39mcoalition_size,\n\u001b[1;32m    259\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    260\u001b[0m )\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.12/site-packages/sharp/base.py:133\u001b[0m, in \u001b[0;36mShaRP.individual\u001b[0;34m(self, sample, X, y, **kwargs)\u001b[0m\n\u001b[1;32m    130\u001b[0m     sample_size \u001b[38;5;241m=\u001b[39m X_\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    132\u001b[0m verbosity \u001b[38;5;241m=\u001b[39m kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mverbose\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs\u001b[38;5;241m.\u001b[39mkeys() \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mverbose\n\u001b[0;32m--> 133\u001b[0m influences \u001b[38;5;241m=\u001b[39m parallel_loop(\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28;01mlambda\u001b[39;00m col_idx: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmeasure_(\n\u001b[1;32m    135\u001b[0m         row\u001b[38;5;241m=\u001b[39msample,\n\u001b[1;32m    136\u001b[0m         col_idx\u001b[38;5;241m=\u001b[39mcol_idx,\n\u001b[1;32m    137\u001b[0m         set_cols_idx\u001b[38;5;241m=\u001b[39mset_cols_idx,\n\u001b[1;32m    138\u001b[0m         X\u001b[38;5;241m=\u001b[39mX_,\n\u001b[1;32m    139\u001b[0m         qoi\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mqoi_,\n\u001b[1;32m    140\u001b[0m         sample_size\u001b[38;5;241m=\u001b[39msample_size,\n\u001b[1;32m    141\u001b[0m         coalition_size\u001b[38;5;241m=\u001b[39mcoalition_size,\n\u001b[1;32m    142\u001b[0m         replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreplace,\n\u001b[1;32m    143\u001b[0m         rng\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_rng,\n\u001b[1;32m    144\u001b[0m     ),\n\u001b[1;32m    145\u001b[0m     \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfeature_names_)),\n\u001b[1;32m    146\u001b[0m     n_jobs\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mn_jobs,\n\u001b[1;32m    147\u001b[0m     progress_bar\u001b[38;5;241m=\u001b[39mverbosity,\n\u001b[1;32m    148\u001b[0m )\n\u001b[1;32m    150\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m influences\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.12/site-packages/sharp/utils/_parallelize.py:112\u001b[0m, in \u001b[0;36mparallel_loop\u001b[0;34m(function, iterable, n_jobs, progress_bar, description)\u001b[0m\n\u001b[1;32m    109\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs)(delayed(function)(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m iterable)\n\u001b[1;32m    111\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 112\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m Parallel(n_jobs\u001b[38;5;241m=\u001b[39mn_jobs)(delayed(function)(i) \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m iterable)\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.12/site-packages/joblib/parallel.py:2007\u001b[0m, in \u001b[0;36mParallel.__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m   2001\u001b[0m \u001b[38;5;66;03m# The first item from the output is blank, but it makes the interpreter\u001b[39;00m\n\u001b[1;32m   2002\u001b[0m \u001b[38;5;66;03m# progress until it enters the Try/Except block of the generator and\u001b[39;00m\n\u001b[1;32m   2003\u001b[0m \u001b[38;5;66;03m# reaches the first `yield` statement. This starts the asynchronous\u001b[39;00m\n\u001b[1;32m   2004\u001b[0m \u001b[38;5;66;03m# dispatch of the tasks to the workers.\u001b[39;00m\n\u001b[1;32m   2005\u001b[0m \u001b[38;5;28mnext\u001b[39m(output)\n\u001b[0;32m-> 2007\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m output \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mreturn_generator \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(output)\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.12/site-packages/joblib/parallel.py:1650\u001b[0m, in \u001b[0;36mParallel._get_outputs\u001b[0;34m(self, iterator, pre_dispatch)\u001b[0m\n\u001b[1;32m   1647\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[1;32m   1649\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backend\u001b[38;5;241m.\u001b[39mretrieval_context():\n\u001b[0;32m-> 1650\u001b[0m         \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_retrieve()\n\u001b[1;32m   1652\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mGeneratorExit\u001b[39;00m:\n\u001b[1;32m   1653\u001b[0m     \u001b[38;5;66;03m# The generator has been garbage collected before being fully\u001b[39;00m\n\u001b[1;32m   1654\u001b[0m     \u001b[38;5;66;03m# consumed. This aborts the remaining tasks if possible and warn\u001b[39;00m\n\u001b[1;32m   1655\u001b[0m     \u001b[38;5;66;03m# the user if necessary.\u001b[39;00m\n\u001b[1;32m   1656\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_exception \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n",
      "File \u001b[0;32m/ext3/miniconda3/lib/python3.12/site-packages/joblib/parallel.py:1762\u001b[0m, in \u001b[0;36mParallel._retrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1757\u001b[0m \u001b[38;5;66;03m# If the next job is not ready for retrieval yet, we just wait for\u001b[39;00m\n\u001b[1;32m   1758\u001b[0m \u001b[38;5;66;03m# async callbacks to progress.\u001b[39;00m\n\u001b[1;32m   1759\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ((\u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[1;32m   1760\u001b[0m     (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_jobs[\u001b[38;5;241m0\u001b[39m]\u001b[38;5;241m.\u001b[39mget_status(\n\u001b[1;32m   1761\u001b[0m         timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtimeout) \u001b[38;5;241m==\u001b[39m TASK_PENDING)):\n\u001b[0;32m-> 1762\u001b[0m     time\u001b[38;5;241m.\u001b[39msleep(\u001b[38;5;241m0.01\u001b[39m)\n\u001b[1;32m   1763\u001b[0m     \u001b[38;5;28;01mcontinue\u001b[39;00m\n\u001b[1;32m   1765\u001b[0m \u001b[38;5;66;03m# We need to be careful: the job list can be filling up as\u001b[39;00m\n\u001b[1;32m   1766\u001b[0m \u001b[38;5;66;03m# we empty it and Python list are not thread-safe by\u001b[39;00m\n\u001b[1;32m   1767\u001b[0m \u001b[38;5;66;03m# default hence the use of the lock\u001b[39;00m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import tqdm\n",
    "import time\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "import itertools\n",
    "import random\n",
    "\n",
    "from sklearn.utils import check_random_state\n",
    "from lightgbm import LGBMRanker\n",
    "from sharp import ShaRP\n",
    "from sharp.utils import scores_to_ordering\n",
    "from xai_ranking.preprocessing import preprocess_higher_education_data\n",
    "from xai_ranking.scorers import higher_education_score\n",
    "from mlresearch.utils import check_random_states\n",
    "\n",
    "from xai_ranking.preprocessing import (\n",
    "    preprocess_atp_data,\n",
    "    preprocess_csrank_data,\n",
    "    preprocess_higher_education_data,\n",
    "    preprocess_movers_data,\n",
    "    preprocess_synthetic_data,\n",
    ")\n",
    "from xai_ranking.datasets import (\n",
    "    fetch_atp_data,\n",
    "    fetch_csrank_data,\n",
    "    fetch_higher_education_data,\n",
    "    fetch_movers_data,\n",
    "    fetch_synthetic_data,\n",
    ")\n",
    "from xai_ranking.scorers import (\n",
    "    atp_score,\n",
    "    csrank_score,\n",
    "    higher_education_score,\n",
    "    synthetic_equal_score_3ftrs,\n",
    ")\n",
    "from xai_ranking.metrics import (\n",
    "    explanation_sensitivity,\n",
    "    outcome_sensitivity,\n",
    "    bootstrapped_explanation_consistency,\n",
    "    cross_method_explanation_consistency,\n",
    "    cross_method_outcome_consistency,\n",
    "    outcome_fidelity,\n",
    ")\n",
    "\n",
    "RNG_SEED = 42\n",
    "N_RUNS = 1\n",
    "\n",
    "# Set up ranker for the moving company dataset:\n",
    "X, ranks, score = preprocess_movers_data(fetch_movers_data(test=False))\n",
    "qids_train = X.index.value_counts().to_numpy()\n",
    "\n",
    "model = LGBMRanker(\n",
    "    objective=\"lambdarank\", label_gain=list(range(max(ranks) + 1)), verbose=-1\n",
    ")\n",
    "model.fit(\n",
    "    X=X,\n",
    "    y=ranks,\n",
    "    group=qids_train,\n",
    ")\n",
    "\n",
    "random_states = check_random_states(RNG_SEED, N_RUNS)\n",
    "\n",
    "datasets = [\n",
    "    {\n",
    "        \"name\": \"Higher Education\",\n",
    "        \"data\": preprocess_higher_education_data(\n",
    "            fetch_higher_education_data(year=2020)\n",
    "        ),\n",
    "        \"scorer\": higher_education_score,\n",
    "        \"n_observations\": 100,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"ATP\",\n",
    "        \"data\": preprocess_atp_data(fetch_atp_data()),\n",
    "        \"scorer\": atp_score,\n",
    "        \"n_observations\": 86,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"CSRank\",\n",
    "        \"data\": preprocess_csrank_data(fetch_csrank_data()),\n",
    "        \"scorer\": csrank_score,\n",
    "        \"n_observations\": 100,\n",
    "    },\n",
    "    # {\n",
    "    #     \"name\": \"Moving Company\",\n",
    "    #     \"data\": preprocess_movers_data(fetch_movers_data(test=True)),\n",
    "    #     \"scorer\": model.predict,\n",
    "    #     \"n_observations\": 100,\n",
    "    # },\n",
    "    {\n",
    "        \"name\": \"Synthetic_0\",\n",
    "        \"data\": preprocess_synthetic_data(\n",
    "            fetch_synthetic_data(synth_dt_version=0, item_num=2000)\n",
    "        ),\n",
    "        \"scorer\": synthetic_equal_score_3ftrs,\n",
    "        \"n_observations\": 100,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Synthetic_1\",\n",
    "        \"data\": preprocess_synthetic_data(\n",
    "            fetch_synthetic_data(synth_dt_version=1, item_num=2000)\n",
    "        ),\n",
    "        \"scorer\": synthetic_equal_score_3ftrs,\n",
    "        \"n_observations\": 100,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Synthetic_2\",\n",
    "        \"data\": preprocess_synthetic_data(\n",
    "            fetch_synthetic_data(synth_dt_version=2, item_num=2000)\n",
    "        ),\n",
    "        \"scorer\": synthetic_equal_score_3ftrs,\n",
    "        \"n_observations\": 100,\n",
    "    },\n",
    "]\n",
    "\n",
    "# approaches = [\"rank\", \"rank_score\", \"pairwise-rank\", \"pairwise-score\"]\n",
    "approaches = [\"pairwise-rank\", \"pairwise-rank_score\"]\n",
    "\n",
    "\n",
    "default_kwargs = {\n",
    "    \"measure\": \"shapley\",\n",
    "    \"sample_size\": None,\n",
    "    \"coalition_size\": None,\n",
    "    \"replace\": False,\n",
    "    \"n_jobs\": 14,\n",
    "}\n",
    "# parameters_to_change = {\n",
    "#     \"coalition_size\": [i for i in range(1, 7)],\n",
    "#     \"sample_size\": [20, 50, 100, 250] + list(range(500, 2000, 500)),\n",
    "#     \"n_jobs\": [1, 2, 4, 8, 16, 32, 48],\n",
    "# }\n",
    "\n",
    "parameters_to_change = {\n",
    "    \"coalition_size\": [i for i in range(1, 7)],\n",
    "    \"sample_size\": [20, 50, 100, 250] + list(range(500, 2000, 500)),\n",
    "}\n",
    "\n",
    "result_cols = (\n",
    "    [\n",
    "        \"dataset\",\n",
    "        \"n_observations\",\n",
    "        \"approach\",\n",
    "        \"parameter\",\n",
    "        \"parameter_value\",\n",
    "        \"avg_time\",\n",
    "    ]\n",
    "    + [f\"time_{i}\" for i in range(N_RUNS)]\n",
    "    + [f\"agreement_kendall_{i}\" for i in range(N_RUNS)]\n",
    "    + [f\"agreement_jaccard2_{i}\" for i in range(N_RUNS)]\n",
    "    + [f\"agreement_euclidean_{i}\" for i in range(N_RUNS)]\n",
    "    + [f\"fidelity_{i}\" for i in range(N_RUNS)]\n",
    ")\n",
    "\n",
    "\n",
    "for dataset in datasets:\n",
    "    result_df = []\n",
    "    # Set up basic settings\n",
    "    X = dataset[\"data\"][0]\n",
    "\n",
    "    # Get scores and ranks\n",
    "    scorer = dataset[\"scorer\"]\n",
    "    scores = np.array(scorer(dataset[\"data\"][0]))\n",
    "\n",
    "    # Remove items that tie\n",
    "    res = [idx for idx, val in enumerate(scores) if val in scores[:idx]]\n",
    "    X = X.drop([X.index[i] for i in res])\n",
    "    # Rescore, get rank\n",
    "    scores = np.array(scorer(X))\n",
    "    ranking = scores_to_ordering(scores)\n",
    "\n",
    "    # Set experiment size if we deleted too many items\n",
    "    dataset[\"n_observations\"] = dataset[\"n_observations\"] if X.shape[0] > dataset[\"n_observations\"] else X.shape[0]\n",
    "    \n",
    "    rng = check_random_state(RNG_SEED)\n",
    "\n",
    "    # rank and score indexes\n",
    "    sam_idx = rng.choice(\n",
    "        np.indices((X.shape[0],)).squeeze(),\n",
    "        size=dataset[\"n_observations\"],\n",
    "        replace=False,\n",
    "    )\n",
    "    \n",
    "    # pairwise pairs\n",
    "    combos = list(itertools.combinations(np.indices((X.shape[0],)).squeeze(), 2))\n",
    "    pairs_indexes = rng.choice(\n",
    "        len(combos),\n",
    "        size=dataset[\"n_observations\"],\n",
    "        replace=False,\n",
    "    )\n",
    "    pairs_sample = [combos[i] for i in pairs_indexes]\n",
    "    pairs = [(pair[0], pair[1]) if np.random.choice([0,1]) else (pair[1], pair[0]) for pair in pairs_sample]\n",
    "\n",
    "    for approach in approaches:\n",
    "        iteration_qoi = approach\n",
    "        if approach.startswith(\"pairwise\"):\n",
    "            iteration_qoi = approach.split(\"-\")[1]\n",
    "            approach = \"pairwise\"\n",
    "        print(\"----------------\", dataset[\"name\"], \"|\", approach, \"|\", iteration_qoi, \"----------------\")\n",
    "\n",
    "        times = []\n",
    "        kendall_cons = []\n",
    "        jaccard_cons = []\n",
    "        euclidean_cons = []\n",
    "        fidelity = []\n",
    "\n",
    "        print(\"Exact computation\")\n",
    "        for i in tqdm.tqdm(range(N_RUNS)):\n",
    "            start = time.time()\n",
    "            if approach != \"pairwise\":\n",
    "                baseline_sharp = ShaRP(\n",
    "                    qoi=iteration_qoi,\n",
    "                    target_function=dataset[\"scorer\"],\n",
    "                    random_state=random_states[i],\n",
    "                    **default_kwargs,\n",
    "                )\n",
    "                baseline_sharp.fit(X)\n",
    "                sam_idx1 = sam_idx\n",
    "                baseline_contr = baseline_sharp.all(X.values[sam_idx1])\n",
    "            else:\n",
    "                baseline_sharp = ShaRP(\n",
    "                    qoi=iteration_qoi,\n",
    "                    target_function=dataset[\"scorer\"],\n",
    "                    random_state=random_states[i],\n",
    "                    **default_kwargs,\n",
    "                )\n",
    "                baseline_sharp.fit(X)\n",
    "                baseline_pairwise = []\n",
    "                sam_idx1 = [i[0] for i in pairs]\n",
    "                sam_idx2 = [i[1] for i in pairs]\n",
    "                for idx1, idx2 in pairs:\n",
    "                    baseline_pairwise.append(\n",
    "                        baseline_sharp.pairwise(X.values[idx1], X.values[idx2])\n",
    "                    )\n",
    "                baseline_contr = np.array(baseline_pairwise)\n",
    "\n",
    "            end = time.time()\n",
    "\n",
    "            baseline_contr = pd.DataFrame(\n",
    "                baseline_contr, columns=X.columns, index=X.index.values[sam_idx1]\n",
    "            )\n",
    "            # Save metrics\n",
    "            times.append(end - start)\n",
    "            kendall_cons.append(np.nan)\n",
    "            jaccard_cons.append(np.nan)\n",
    "            euclidean_cons.append(np.nan)\n",
    "\n",
    "            target = scores if approach == \"rank_score\" else ranking\n",
    "            avg_target = target.mean()\n",
    "            if approach != \"pairwise\":\n",
    "                res_ = outcome_fidelity(\n",
    "                    baseline_contr,\n",
    "                    target[sam_idx1],\n",
    "                    avg_target,\n",
    "                    target_max=X.shape[0] if approach == \"rank\" else target.max(),\n",
    "                    rank=approach == \"rank\",\n",
    "                )\n",
    "            else:\n",
    "                res_ = outcome_fidelity(\n",
    "                    baseline_contr,\n",
    "                    target[sam_idx1],\n",
    "                    avg_target,\n",
    "                    target_max=X.shape[0] if approach == \"rank\" else target.max(),\n",
    "                    target_pairs=target[sam_idx2],\n",
    "                    rank=True,\n",
    "                )\n",
    "\n",
    "            fidelity.append(res_)\n",
    "\n",
    "        exact_results_row = (\n",
    "            [\n",
    "                dataset[\"name\"],\n",
    "                dataset[\"n_observations\"],\n",
    "                approach,\n",
    "                np.nan,\n",
    "                np.nan,\n",
    "                np.mean(times),\n",
    "            ]\n",
    "            + times\n",
    "            + kendall_cons\n",
    "            + jaccard_cons\n",
    "            + euclidean_cons\n",
    "            + fidelity\n",
    "        )\n",
    "        result_df.append(exact_results_row)\n",
    "        print(\"Finished computing exact results\")\n",
    "        ############################################################################################\n",
    "\n",
    "        for parameter, parameter_values in parameters_to_change.items():\n",
    "            print(f\"Alternating parameter: {parameter}\")\n",
    "            default_value = deepcopy(\n",
    "                default_kwargs[parameter] if parameter in default_kwargs else None\n",
    "            )\n",
    "\n",
    "            if parameter == \"coalition_size\":\n",
    "                parameter_values = [\n",
    "                    val for val in parameter_values if X.shape[-1] > val\n",
    "                ]\n",
    "            if parameter == \"sample_size\":\n",
    "                parameter_values = [\n",
    "                    val for val in parameter_values if X.shape[0] >= val\n",
    "                ] + [X.shape[0]]\n",
    "\n",
    "            if approach == \"pairwise\" and parameter == \"sample_size\":\n",
    "                continue\n",
    "\n",
    "            for parameter_value in tqdm.tqdm(parameter_values):\n",
    "\n",
    "                default_kwargs[parameter] = parameter_value\n",
    "\n",
    "                times = []\n",
    "                kendall_cons = []\n",
    "                jaccard_cons = []\n",
    "                euclidean_cons = []\n",
    "                fidelity = []\n",
    "\n",
    "                print(f\"Parameter {parameter}, value {parameter_value}\")\n",
    "                for i in tqdm.tqdm(range(N_RUNS)):\n",
    "                    start = time.time()\n",
    "                    if approach != \"pairwise\":\n",
    "                        sharp = ShaRP(\n",
    "                            qoi=iteration_qoi,\n",
    "                            target_function=dataset[\"scorer\"],\n",
    "                            random_state=random_states[i],\n",
    "                            **default_kwargs,\n",
    "                        )\n",
    "                        sharp.fit(X)\n",
    "                        sam_idx1 = sam_idx\n",
    "                        contr = sharp.all(X.values[sam_idx1])\n",
    "                    else:\n",
    "                        sharp = ShaRP(\n",
    "                            qoi=iteration_qoi,\n",
    "                            target_function=dataset[\"scorer\"],\n",
    "                            random_state=random_states[i],\n",
    "                            **default_kwargs,\n",
    "                        )\n",
    "                        sharp.fit(X)\n",
    "                        pairwise = []\n",
    "                        sam_idx1 = [i[0] for i in pairs]\n",
    "                        sam_idx2 = [i[1] for i in pairs]\n",
    "                        for idx1, idx2 in pairs:\n",
    "                            pairwise.append(\n",
    "                                sharp.pairwise(X.values[idx1], X.values[idx2])\n",
    "                            )\n",
    "                        contr = np.array(pairwise)\n",
    "\n",
    "                    end = time.time()\n",
    "\n",
    "                    contr = pd.DataFrame(\n",
    "                        contr, columns=X.columns, index=np.array(X.index)[sam_idx1]\n",
    "                    )\n",
    "\n",
    "                    # Save metrics\n",
    "                    times.append(end - start)\n",
    "                    # Kendall consistency\n",
    "                    kendall_cons.append(\n",
    "                        cross_method_explanation_consistency(\n",
    "                            contr, baseline_contr, measure=\"kendall\"\n",
    "                        )[0]\n",
    "                    )\n",
    "                    # Jaccard consistency\n",
    "                    jaccard_cons.append(\n",
    "                        cross_method_explanation_consistency(\n",
    "                            contr, baseline_contr, measure=\"jaccard\", n_features=2\n",
    "                        )[0]\n",
    "                    )\n",
    "                    # Iniatialize normalizer\n",
    "                    target = scores if approach == \"rank_score\" else ranking\n",
    "                    avg_target = target.mean()\n",
    "                    max_target = X.shape[0] if approach == \"rank\" else target.max()\n",
    "                    #Eulidean consistency\n",
    "                    euclidean_cons.append(\n",
    "                        cross_method_explanation_consistency(\n",
    "                            contr, baseline_contr, measure=\"euclidean\", normalizer=max_target\n",
    "                        )[0]\n",
    "                    )\n",
    "                    # Fidelity\n",
    "                    if approach != \"pairwise\":\n",
    "                        res_ = outcome_fidelity(\n",
    "                            contr,\n",
    "                            target[sam_idx1],\n",
    "                            avg_target,\n",
    "                            target_max=max_target,\n",
    "                            rank=approach == \"rank\",\n",
    "                        )\n",
    "                    else:\n",
    "                        res_ = outcome_fidelity(\n",
    "                            contr,\n",
    "                            target[sam_idx1],\n",
    "                            avg_target,\n",
    "                            target_max=max_target,\n",
    "                            target_pairs=target[sam_idx2],\n",
    "                            rank=True,\n",
    "                        )\n",
    "        \n",
    "                    fidelity.append(res_)\n",
    "\n",
    "                results_row = (\n",
    "                    [\n",
    "                        dataset[\"name\"],\n",
    "                        dataset[\"n_observations\"],\n",
    "                        approach+\"_\"+iteration_qoi,\n",
    "                        parameter,\n",
    "                        parameter_value,\n",
    "                        np.mean(times),\n",
    "                    ]\n",
    "                    + times\n",
    "                    + kendall_cons\n",
    "                    + jaccard_cons\n",
    "                    + euclidean_cons\n",
    "                    + fidelity\n",
    "                )\n",
    "                result_df.append(results_row)\n",
    "                print(f\"Stored results for {parameter} | {parameter_value}\")\n",
    "\n",
    "            default_kwargs[parameter] = default_value\n",
    "\n",
    "    results = pd.DataFrame(result_df, columns=result_cols)\n",
    "    print(results)\n",
    "    # results.to_csv(\"notebooks/results/time-experiment-\" + dataset[\"name\"] + \".csv\")\n",
    "\n",
    "results = pd.DataFrame(result_df, columns=result_cols)\n",
    "results\n",
    "\n",
    "metric = \"exp_cons_kendall\"\n",
    "col_mask = results.columns.str.startswith(metric)\n",
    "results[f\"avg_{metric}\"] = results.iloc[:, col_mask].mean(1)\n",
    "col_mask = results.columns == f\"avg_{metric}\"\n",
    "col_mask[:6] = True\n",
    "results.iloc[:, col_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "827cb828-159f-4782-bbe5-765c78c7f587",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = [[1,4,3,2], [1,1,1,1], [1,1,2,2], [1,2,2,2], [1,1,2,2], [1,2,3,1], [1,3,2,1], [1,1,2,3],\n",
    "    [1,2,3,4], [1,1,2,1]]\n",
    "b = [[1,4,3,2], [1,1,1,1], [1,1,2,2], [1,2,2,2], [2,2,1,1], [1,2,3,1], [1,3,2,1], [1,1,2,3],\n",
    "    [1,1,3,3], [1,1,1,1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8f7c7c5e-ed2d-4df8-8b62-a209678f4dd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sharp.utils import scores_to_ordering\n",
    "from scipy import stats\n",
    "\n",
    "def kendall_agreement(results1, results2):\n",
    "    return results1.reset_index(drop=True).apply(\n",
    "        lambda row: row_wise_kendall(row, results2.iloc[row.name]), axis=1\n",
    "    )\n",
    "\n",
    "def row_wise_kendall(results1, results2):\n",
    "    results = [results1, results2]\n",
    "\n",
    "    print(\"Item1: \", results1.values)\n",
    "    print(\"Item2: \", results2.values)\n",
    "    # Check for ties\n",
    "    ranks = []\n",
    "    for result in results:\n",
    "        rank = scores_to_ordering(result, direction=1)\n",
    "        # Correct rank values to reflect ties\n",
    "        for val in result:\n",
    "            mask = result == val\n",
    "            if mask.sum() > 1:\n",
    "                rank[mask] = rank[mask].max()\n",
    "        ranks.append(rank)\n",
    "\n",
    "    row_sensitivity = kendall_similarity(*ranks)\n",
    "    # row_sensitivity = kendall_similarity(*results)\n",
    "    return row_sensitivity\n",
    "\n",
    "# def kendall_similarity(a, b):\n",
    "#     normalizer = (len(a) * (len(a) - 1)) / 2\n",
    "#     idx_pair = list(combinations(range(len(a)), 2))\n",
    "#     val_pair_a = [(a[i], a[j]) for i, j in idx_pair if a[i] != a[j]]\n",
    "#     val_pair_b = [(b[i], b[j]) for i, j in idx_pair if b[i] != b[j]]\n",
    "#     inversions = sum([(val2, val1) in val_pair_b for val1, val2 in val_pair_a])\n",
    "#     return (normalizer - inversions) / normalizer\n",
    "\n",
    "def kendall_similarity(a, b):\n",
    "    # return 1 - (stats.kendalltau(a, b).statistic + 1) / 2\n",
    "    print(\"Rank1: \",a)\n",
    "    print(\"Rank2: \",b)\n",
    "    \n",
    "    stat = stats.kendalltau(a, b).statistic\n",
    "    print(\"Kt-o:\", stat)\n",
    "    print(\"Kt-n:\", 1 - (stat + 1) / 2)\n",
    "    print(\"Kt-l\", (stat * (-1) + 1) / 2)\n",
    "    # return stat\n",
    "    return 1 - (stat + 1) / 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "2ba9c645-2bcc-433d-8baa-c4b84ee3ebc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item1:  [1 4 3 2]\n",
      "Item2:  [1 4 3 2]\n",
      "Rank1:  [1 4 3 2]\n",
      "Rank2:  [1 4 3 2]\n",
      "Kt-o: 1.0\n",
      "Kt-n: 0.0\n",
      "Kt-l 0.0\n",
      "Item1:  [1 1 1 1]\n",
      "Item2:  [1 1 1 1]\n",
      "Rank1:  [4 4 4 4]\n",
      "Rank2:  [4 4 4 4]\n",
      "Kt-o: nan\n",
      "Kt-n: nan\n",
      "Kt-l nan\n",
      "Item1:  [1 1 2 2]\n",
      "Item2:  [1 1 2 2]\n",
      "Rank1:  [2 2 4 4]\n",
      "Rank2:  [2 2 4 4]\n",
      "Kt-o: 1.0\n",
      "Kt-n: 0.0\n",
      "Kt-l 0.0\n",
      "Item1:  [1 2 2 2]\n",
      "Item2:  [1 2 2 2]\n",
      "Rank1:  [1 4 4 4]\n",
      "Rank2:  [1 4 4 4]\n",
      "Kt-o: 1.0\n",
      "Kt-n: 0.0\n",
      "Kt-l 0.0\n",
      "Item1:  [1 1 2 2]\n",
      "Item2:  [2 2 1 1]\n",
      "Rank1:  [2 2 4 4]\n",
      "Rank2:  [4 4 2 2]\n",
      "Kt-o: -1.0\n",
      "Kt-n: 1.0\n",
      "Kt-l 1.0\n",
      "Item1:  [1 2 3 1]\n",
      "Item2:  [1 2 3 1]\n",
      "Rank1:  [2 3 4 2]\n",
      "Rank2:  [2 3 4 2]\n",
      "Kt-o: 1.0\n",
      "Kt-n: 0.0\n",
      "Kt-l 0.0\n",
      "Item1:  [1 3 2 1]\n",
      "Item2:  [1 3 2 1]\n",
      "Rank1:  [2 4 3 2]\n",
      "Rank2:  [2 4 3 2]\n",
      "Kt-o: 1.0\n",
      "Kt-n: 0.0\n",
      "Kt-l 0.0\n",
      "Item1:  [1 1 2 3]\n",
      "Item2:  [1 1 2 3]\n",
      "Rank1:  [2 2 3 4]\n",
      "Rank2:  [2 2 3 4]\n",
      "Kt-o: 1.0\n",
      "Kt-n: 0.0\n",
      "Kt-l 0.0\n",
      "Item1:  [1 2 3 4]\n",
      "Item2:  [1 1 3 3]\n",
      "Rank1:  [1 2 3 4]\n",
      "Rank2:  [2 2 4 4]\n",
      "Kt-o: 0.8164965809277261\n",
      "Kt-n: 0.09175170953613687\n",
      "Kt-l 0.09175170953613693\n",
      "Item1:  [1 1 2 1]\n",
      "Item2:  [1 1 1 1]\n",
      "Rank1:  [3 3 4 3]\n",
      "Rank2:  [4 4 4 4]\n",
      "Kt-o: nan\n",
      "Kt-n: nan\n",
      "Kt-l nan\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.000000\n",
       "1         NaN\n",
       "2    0.000000\n",
       "3    0.000000\n",
       "4    1.000000\n",
       "5    0.000000\n",
       "6    0.000000\n",
       "7    0.000000\n",
       "8    0.091752\n",
       "9         NaN\n",
       "dtype: float64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# a = [[-10,-6,-4,4,6,10],[-10,-10,-10,0,0,0],[-10,-10,-10,0,0,0],[-10,-8,-6,0,6,8], [-10,-10,-10,0,0,0],[-10,-10,-10,0,0,0],\n",
    "#      [-10,-10,-10,0,0,0]]\n",
    "# b = [[-10,-6,-4,4,6,10],[-10,-10,-10,0,0,0],[-10,-10,-10,0,0,-10],[8,6,0,-6,-8,-10], [-10,-9,-8,0,1,2],[-10,-10,-9,0,1,0],\n",
    "#      [-10,-10,-10,0,0,1]]\n",
    "\n",
    "kendall_agreement(pd.DataFrame(a), pd.DataFrame(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "83d5651e-d549-4400-bf08-24bb8aa40e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pandas as pd\n",
    "# from sharp.utils import scores_to_ordering\n",
    "# from itertools import product, combinations\n",
    "\n",
    "# def kendall_agreement(results1, results2):\n",
    "#     return results1.reset_index(drop=True).apply(\n",
    "#         lambda row: row_wise_kendall(row, results2.iloc[row.name]), axis=1\n",
    "#     )\n",
    "\n",
    "# def row_wise_kendall(results1, results2):\n",
    "#     results = [results1, results2]\n",
    "\n",
    "#     print(\"Item1: \", results1.values)\n",
    "#     print(\"Item2: \", results2.values)\n",
    "#     # Check for ties\n",
    "#     ranks = []\n",
    "#     for result in results:\n",
    "#         rank = scores_to_ordering(result, direction=1)\n",
    "#         # Correct rank values to reflect ties\n",
    "#         for val in result:\n",
    "#             mask = result == val\n",
    "#             if mask.sum() > 1:\n",
    "#                 rank[mask] = rank[mask].max()\n",
    "#         ranks.append(rank)\n",
    "\n",
    "#     row_sensitivity = kendall_similarity(*ranks)\n",
    "#     # row_sensitivity = kendall_similarity(*results)\n",
    "#     return row_sensitivity\n",
    "\n",
    "# def kendall_similarity(a, b):\n",
    "#     print(\"Rank1: \",a)\n",
    "#     print(\"Rank2: \",b)\n",
    "#     normalizer = (len(a) * (len(a) - 1)) / 2\n",
    "#     idx_pair = list(combinations(range(len(a)), 2))\n",
    "#     val_pair_a = [(a[i], a[j]) for i, j in idx_pair if a[i] != a[j]]\n",
    "#     val_pair_b = [(b[i], b[j]) for i, j in idx_pair if b[i] != b[j]]\n",
    "#     print(val_pair_a)\n",
    "#     print(val_pair_b)\n",
    "#     print([(val2, val1) in val_pair_b for val1, val2 in val_pair_a])\n",
    "#     inversions = sum([(val2, val1) in val_pair_b for val1, val2 in val_pair_a])\n",
    "#     kt = 1 - (2 * inversions) / normalizer\n",
    "#     print(\"Kt-o:\", kt)\n",
    "#     print(\"Kt-n:\", (normalizer - inversions) / normalizer)\n",
    "#     return (normalizer - inversions) / normalizer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "391d5750-ea49-44ca-8339-49693e1dfcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = [[-10,-6,-4,4,6,10],[-10,-10,-10,0,0,0],[-10,-10,-10,0,0,0],[-10,-8,-6,0,6,8], [-10,-10,-10,0,0,0],[-10,-10,-10,0,0,0],\n",
    "#      [-10,-10,-10,0,0,0],[1,2,3,4,5,6]]\n",
    "# b = [[-10,-6,-4,4,6,10],[-10,-10,-10,0,0,0],[-10,-10,-10,0,0,-10],[8,6,0,-6,-8,-10], [-10,-9,-8,0,1,2],[-10,-10,-9,0,1,0],\n",
    "#      [-10,-10,-10,0,0,1],[21,30,12,1,5,3]]\n",
    "\n",
    "# kendall_agreement(pd.DataFrame(a), pd.DataFrame(b))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "341d2582-9237-420b-bb5c-af260813b72d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sharp.utils import scores_to_ordering\n",
    "from itertools import product, combinations\n",
    "\n",
    "def kendall_agreement(results1, results2):\n",
    "    return results1.reset_index(drop=True).apply(\n",
    "        lambda row: row_wise_kendall(row, results2.iloc[row.name]), axis=1\n",
    "    )\n",
    "\n",
    "def row_wise_kendall(results1, results2):\n",
    "    results = [results1, results2]\n",
    "\n",
    "    print(\"Item1: \", results1.values)\n",
    "    print(\"Item2: \", results2.values)\n",
    "    # Check for ties\n",
    "    ranks = []\n",
    "    for result in results:\n",
    "        rank = scores_to_ordering(result, direction=1)\n",
    "        # Correct rank values to reflect ties\n",
    "        for val in result:\n",
    "            mask = result == val\n",
    "            if mask.sum() > 1:\n",
    "                rank[mask] = rank[mask].max()\n",
    "        ranks.append(rank)\n",
    "\n",
    "    row_sensitivity = kendall_similarity(*ranks)\n",
    "    # row_sensitivity = kendall_similarity(*results)\n",
    "    return row_sensitivity\n",
    "\n",
    "def kendall_similarity(a, b):\n",
    "    print(\"Rank1: \",a)\n",
    "    print(\"Rank2: \",b)\n",
    "    normalizer = (len(a) * (len(a) - 1)) / 2\n",
    "    idx_pair = list(combinations(range(len(a)), 2))\n",
    "    val_pair_a = [(a[i], a[j]) for i, j in idx_pair if a[i] != a[j]]\n",
    "    val_pair_b = [(b[i], b[j]) for i, j in idx_pair if b[i] != b[j]]\n",
    "    print(val_pair_a)\n",
    "    print(val_pair_b)\n",
    "    inversions=0\n",
    "    for (val11, val12), (val21, val22) in zip(val_pair_a, val_pair_b):\n",
    "        if ((val11 > val12) and (val21 < val22)) or ((val11 < val12) and (val21 > val22)):\n",
    "            inversions = inversions+1\n",
    "    kt = 1 - (2 * inversions) / normalizer\n",
    "    print(\"Kt-o:\", kt)\n",
    "    print(\"Kt-n:\", 1 - (kt + 1) / 2)\n",
    "    return 1 - (kt + 1) / 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9fddcf77-d108-4e79-817b-6e0b108ac9d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Item1:  [1 4 3 2]\n",
      "Item2:  [1 4 3 2]\n",
      "Rank1:  [1 4 3 2]\n",
      "Rank2:  [1 4 3 2]\n",
      "[(1, 4), (1, 3), (1, 2), (4, 3), (4, 2), (3, 2)]\n",
      "[(1, 4), (1, 3), (1, 2), (4, 3), (4, 2), (3, 2)]\n",
      "Kt-o: 1.0\n",
      "Kt-n: 0.0\n",
      "Item1:  [1 1 1 1]\n",
      "Item2:  [1 1 1 1]\n",
      "Rank1:  [4 4 4 4]\n",
      "Rank2:  [4 4 4 4]\n",
      "[]\n",
      "[]\n",
      "Kt-o: 1.0\n",
      "Kt-n: 0.0\n",
      "Item1:  [1 1 2 2]\n",
      "Item2:  [1 1 2 2]\n",
      "Rank1:  [2 2 4 4]\n",
      "Rank2:  [2 2 4 4]\n",
      "[(2, 4), (2, 4), (2, 4), (2, 4)]\n",
      "[(2, 4), (2, 4), (2, 4), (2, 4)]\n",
      "Kt-o: 1.0\n",
      "Kt-n: 0.0\n",
      "Item1:  [1 2 2 2]\n",
      "Item2:  [1 2 2 2]\n",
      "Rank1:  [1 4 4 4]\n",
      "Rank2:  [1 4 4 4]\n",
      "[(1, 4), (1, 4), (1, 4)]\n",
      "[(1, 4), (1, 4), (1, 4)]\n",
      "Kt-o: 1.0\n",
      "Kt-n: 0.0\n",
      "Item1:  [1 1 2 2]\n",
      "Item2:  [2 2 1 1]\n",
      "Rank1:  [2 2 4 4]\n",
      "Rank2:  [4 4 2 2]\n",
      "[(2, 4), (2, 4), (2, 4), (2, 4)]\n",
      "[(4, 2), (4, 2), (4, 2), (4, 2)]\n",
      "Kt-o: -0.33333333333333326\n",
      "Kt-n: 0.6666666666666666\n",
      "Item1:  [1 2 3 1]\n",
      "Item2:  [1 2 3 1]\n",
      "Rank1:  [2 3 4 2]\n",
      "Rank2:  [2 3 4 2]\n",
      "[(2, 3), (2, 4), (3, 4), (3, 2), (4, 2)]\n",
      "[(2, 3), (2, 4), (3, 4), (3, 2), (4, 2)]\n",
      "Kt-o: 1.0\n",
      "Kt-n: 0.0\n",
      "Item1:  [1 3 2 1]\n",
      "Item2:  [1 3 2 1]\n",
      "Rank1:  [2 4 3 2]\n",
      "Rank2:  [2 4 3 2]\n",
      "[(2, 4), (2, 3), (4, 3), (4, 2), (3, 2)]\n",
      "[(2, 4), (2, 3), (4, 3), (4, 2), (3, 2)]\n",
      "Kt-o: 1.0\n",
      "Kt-n: 0.0\n",
      "Item1:  [1 1 2 3]\n",
      "Item2:  [1 1 2 3]\n",
      "Rank1:  [2 2 3 4]\n",
      "Rank2:  [2 2 3 4]\n",
      "[(2, 3), (2, 4), (2, 3), (2, 4), (3, 4)]\n",
      "[(2, 3), (2, 4), (2, 3), (2, 4), (3, 4)]\n",
      "Kt-o: 1.0\n",
      "Kt-n: 0.0\n",
      "Item1:  [1 2 3 4]\n",
      "Item2:  [1 1 3 3]\n",
      "Rank1:  [1 2 3 4]\n",
      "Rank2:  [2 2 4 4]\n",
      "[(1, 2), (1, 3), (1, 4), (2, 3), (2, 4), (3, 4)]\n",
      "[(2, 4), (2, 4), (2, 4), (2, 4)]\n",
      "Kt-o: 1.0\n",
      "Kt-n: 0.0\n",
      "Item1:  [1 1 2 1]\n",
      "Item2:  [1 1 1 1]\n",
      "Rank1:  [3 3 4 3]\n",
      "Rank2:  [4 4 4 4]\n",
      "[(3, 4), (3, 4), (4, 3)]\n",
      "[]\n",
      "Kt-o: 1.0\n",
      "Kt-n: 0.0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    0.000000\n",
       "1    0.000000\n",
       "2    0.000000\n",
       "3    0.000000\n",
       "4    0.666667\n",
       "5    0.000000\n",
       "6    0.000000\n",
       "7    0.000000\n",
       "8    0.000000\n",
       "9    0.000000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kendall_agreement(pd.DataFrame(a), pd.DataFrame(b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45051ee1-55dd-45ef-a0a2-612fc682f696",
   "metadata": {},
   "source": [
    "# Jaccard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "74dcc006-5140-48c3-8ade-a0cbb9161e97",
   "metadata": {},
   "outputs": [],
   "source": [
    "from itertools import product, combinations\n",
    "from sharp.utils import scores_to_ordering\n",
    "\n",
    "a = [[3.2, -5.1, 4, 0],\n",
    "    [3.2, -5.1, 4, 0],\n",
    "    [3.2, -5.1, 4, 0],\n",
    "    [3.2, -5.1, 4, 0],\n",
    "    [3.2, 3.2, 3.2, 3.2]]\n",
    "\n",
    "b = [[3.9, -3.1, 4.1, 0],\n",
    "    [3.2, -5.1, 3.2, 0],\n",
    "    [4, -5.1, 3.2, 0],\n",
    "    [4, -5.1, 3.2, 3.2],\n",
    "    [3, 3, 3, 3]]\n",
    "\n",
    "\n",
    "def _get_importance_mask(row_cont, threshold):\n",
    "    if threshold >= 1:\n",
    "        # Calculate order of absolute contributions\n",
    "        row_abs = np.abs(row_cont)\n",
    "        print(row_abs)\n",
    "        # Find n=threshold largest items\n",
    "        res = sorted(row_abs.index.values, key = lambda sub: row_abs[sub])[-threshold:]\n",
    "        # Set mask\n",
    "        mask = pd.Series(data=[True if i in res else False for i in row_cont.index.values],\n",
    "                         index=row_cont.index.values)\n",
    "    else:\n",
    "        # Calculate cumulative absolute contribution order\n",
    "        total_contribution = np.sum(np.abs(row_cont))\n",
    "        order = np.argsort(np.abs(row_cont))\n",
    "        cumulative_cont = np.cumsum(np.abs(row_cont)[order]) / total_contribution\n",
    "        # Find elements withe the smallest contribution\n",
    "        # (to meet the threshold it's easier to do the reverse operation)\n",
    "        mask = (cumulative_cont < 1 - threshold)[order]\n",
    "        # Reverse array\n",
    "        mask = ~mask\n",
    "\n",
    "    print(mask)\n",
    "\n",
    "    # Check whether ties exist\n",
    "    possible_configs = [mask.copy()]\n",
    "    tie_values = [\n",
    "        (idx_old, cont)\n",
    "        for idx_old, cont in row_cont[mask].items()\n",
    "        if cont in row_cont[~mask].values\n",
    "    ]\n",
    "    print(tie_values)\n",
    "    # Make all possible sets of ties\n",
    "    for idx_old, tie_val in tie_values:\n",
    "        # idx_new = np.where(row_cont == tie_val)[0]\n",
    "        idx_new = row_cont[row_cont == tie_val].index.values\n",
    "        print(\"Substituting:\", idx_new )\n",
    "        # Exclude all selected indexes that have the same value\n",
    "        idx_new = list(set(idx_new).difference(mask[mask].index.values))\n",
    "        print(list(set(idx_new)))\n",
    "        print(\"Substituting 2:\", idx_new )\n",
    "        for idx in idx_new:\n",
    "            new_mask = mask.copy()\n",
    "            new_mask[idx_old] = False\n",
    "            new_mask[idx] = True\n",
    "            possible_configs.append(new_mask)\n",
    "\n",
    "    print(\"Possible configs:\")\n",
    "    print(possible_configs)\n",
    "    return possible_configs\n",
    "\n",
    "def jaccard_similarity(a, b):\n",
    "    intersection = len(list(set(a).intersection(b)))\n",
    "    union = (len(set(a)) + len(set(b))) - intersection\n",
    "    return float(intersection) / union\n",
    "\n",
    "def row_wise_jaccard(results1, results2, n_features):\n",
    "    \"\"\"\n",
    "    Calculate the row-wise Jaccard similarity between two sets of results.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    results1 : numpy.ndarray\n",
    "        The first set of results. It should be a 2-dimensional array with shape\n",
    "        (n_samples, n_features).\n",
    "    results2 : numpy.ndarray\n",
    "        The second set of results. It should be a 2-dimensional array with shape\n",
    "        (n_samples, n_features).\n",
    "    n_features : int, float or None, default=0.8\n",
    "        The number of top features to consider. If None, all features are\n",
    "        considered. If an integer value is provided, only the top n_features\n",
    "        features are considered. If n_features < 1, the most\n",
    "        important features are determined based on their contribution to the\n",
    "        total score (as a percentage of the total contribution in absolute\n",
    "        values).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    float\n",
    "        The row-wise Jaccard similarity between the two sets of results.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The row-wise Jaccard similarity is calculated by first converting the\n",
    "    results into rankings using the `scores_to_ordering` function. Then, the top\n",
    "    n_features features are selected based on the rankings. Finally, the Jaccard\n",
    "    similarity is calculated between the selected features for each row.\n",
    "\n",
    "    If n_features is less than 1, the most important features are determined\n",
    "    based on their contribution to the total score.  The cumulative contribution\n",
    "    of each feature is calculated and the features are selected until the\n",
    "    cumulative contribution exceeds 1 - n_features.\n",
    "\n",
    "    Examples\n",
    "    --------\n",
    "    >>> results1 = np.array([[0.1, 0.2, 0.3], [0.4, 0.5, 0.6]])\n",
    "    >>> results2 = np.array([[0.2, 0.3, 0.4], [0.5, 0.6, 0.7]])\n",
    "    >>> n_features = 2\n",
    "    >>> row_wise_jaccard(results1, results2, n_features)\n",
    "    \"\"\"\n",
    "\n",
    "    print(\"##############\")\n",
    "    print(results1)\n",
    "    print(results2)\n",
    "    \n",
    "    if n_features is None:\n",
    "        n_features = results1.shape[1]\n",
    "\n",
    "    masks1 = _get_importance_mask(results1, n_features)\n",
    "    masks2 = _get_importance_mask(results2, n_features)\n",
    "\n",
    "    row_similarities = []\n",
    "    for mask1, mask2 in product(masks1, masks2):\n",
    "        print(\"Checking\")\n",
    "        top_idx1 = mask1[mask1].index.values\n",
    "        top_idx2 = mask2[mask2].index.values\n",
    "        print(top_idx1)\n",
    "        print(top_idx2)\n",
    "        row_similarity = jaccard_similarity(top_idx1, top_idx2)\n",
    "        row_similarities.append(row_similarity)\n",
    "    return min(row_similarities)\n",
    "\n",
    "def jaccard_agreement(results1, results2, n_features=0.8):\n",
    "    \"\"\"\n",
    "    Calculate the Jaccard similarity between two sets of results. Results are\n",
    "    normalized, 0 means most dis-similar and 1 means most similar.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    results1 : pandas.DataFrame\n",
    "        The first set of results.\n",
    "    results2 : pandas.DataFrame\n",
    "        The second set of results.\n",
    "    n_features : int, float or None, default=0.8\n",
    "        The number of top features to consider. If None, all features are\n",
    "        considered. If an integer value is provided, only the top n_features\n",
    "        features are considered. If n_features < 1, the most\n",
    "        important features are determined based on their contribution to the\n",
    "        total score (as a percentage of the total contribution in absolute\n",
    "        values).\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    pandas.Series\n",
    "        The Jaccard agreement between each pair of results.\n",
    "\n",
    "    Notes\n",
    "    -----\n",
    "    The Jaccard agreement is a measure of similarity between two sets of\n",
    "    results. It is calculated as the average Jaccard similarity coefficient\n",
    "    between each pair of results.\n",
    "    \"\"\"\n",
    "    if n_features is None:\n",
    "        n_features = results1.shape[1]\n",
    "\n",
    "    return results1.reset_index(drop=True).apply(\n",
    "        lambda row: row_wise_jaccard(row, results2.iloc[row.name], n_features),\n",
    "        axis=1,\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4f5e83e2-e3c6-4f00-a6f5-f79d83ff4a50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "##############\n",
      "teaching        -0.428721\n",
      "research        -2.801417\n",
      "citations        6.815626\n",
      "income          -0.092408\n",
      "international   -1.213119\n",
      "Name: 0, dtype: float64\n",
      "teaching         -0.714536\n",
      "research         -4.669028\n",
      "citations        11.359376\n",
      "income           -0.154013\n",
      "international    -2.021865\n",
      "Name: 0, dtype: float64\n",
      "research          True\n",
      "income           False\n",
      "citations         True\n",
      "teaching         False\n",
      "international    False\n",
      "Name: 0, dtype: bool\n",
      "[]\n",
      "Possible configs:\n",
      "[research          True\n",
      "income           False\n",
      "citations         True\n",
      "teaching         False\n",
      "international    False\n",
      "Name: 0, dtype: bool]\n",
      "research          True\n",
      "income           False\n",
      "citations         True\n",
      "teaching         False\n",
      "international    False\n",
      "Name: 0, dtype: bool\n",
      "[]\n",
      "Possible configs:\n",
      "[research          True\n",
      "income           False\n",
      "citations         True\n",
      "teaching         False\n",
      "international    False\n",
      "Name: 0, dtype: bool]\n",
      "Checking\n",
      "['research' 'citations']\n",
      "['research' 'citations']\n",
      "##############\n",
      "teaching        -0.428721\n",
      "research        -2.801417\n",
      "citations        6.815626\n",
      "income          -0.092408\n",
      "international   -2.801417\n",
      "Name: 1, dtype: float64\n",
      "teaching        -0.428721\n",
      "research        -2.801417\n",
      "citations        6.815626\n",
      "income          -0.092408\n",
      "international   -2.801417\n",
      "Name: 1, dtype: float64\n",
      "international     True\n",
      "income           False\n",
      "teaching         False\n",
      "citations         True\n",
      "research         False\n",
      "Name: 1, dtype: bool\n",
      "[('international', -2.801417)]\n",
      "Substituting: ['research' 'international']\n",
      "['research']\n",
      "Substituting 2: ['research']\n",
      "Possible configs:\n",
      "[international     True\n",
      "income           False\n",
      "teaching         False\n",
      "citations         True\n",
      "research         False\n",
      "Name: 1, dtype: bool, international    False\n",
      "income           False\n",
      "teaching         False\n",
      "citations         True\n",
      "research          True\n",
      "Name: 1, dtype: bool]\n",
      "international     True\n",
      "income           False\n",
      "teaching         False\n",
      "citations         True\n",
      "research         False\n",
      "Name: 1, dtype: bool\n",
      "[('international', -2.801417)]\n",
      "Substituting: ['research' 'international']\n",
      "['research']\n",
      "Substituting 2: ['research']\n",
      "Possible configs:\n",
      "[international     True\n",
      "income           False\n",
      "teaching         False\n",
      "citations         True\n",
      "research         False\n",
      "Name: 1, dtype: bool, international    False\n",
      "income           False\n",
      "teaching         False\n",
      "citations         True\n",
      "research          True\n",
      "Name: 1, dtype: bool]\n",
      "Checking\n",
      "['international' 'citations']\n",
      "['international' 'citations']\n",
      "Checking\n",
      "['international' 'citations']\n",
      "['citations' 'research']\n",
      "Checking\n",
      "['citations' 'research']\n",
      "['international' 'citations']\n",
      "Checking\n",
      "['citations' 'research']\n",
      "['citations' 'research']\n",
      "##############\n",
      "teaching        -2.801417\n",
      "research        -2.801417\n",
      "citations        6.815626\n",
      "income          -0.092408\n",
      "international   -2.801417\n",
      "Name: 2, dtype: float64\n",
      "teaching        -2.801417\n",
      "research        -2.801417\n",
      "citations        6.815626\n",
      "income          -0.092408\n",
      "international   -2.801417\n",
      "Name: 2, dtype: float64\n",
      "international     True\n",
      "income           False\n",
      "teaching         False\n",
      "citations         True\n",
      "research          True\n",
      "Name: 2, dtype: bool\n",
      "[('research', -2.801417), ('international', -2.801417)]\n",
      "Substituting: ['teaching' 'research' 'international']\n",
      "['teaching']\n",
      "Substituting 2: ['teaching']\n",
      "Substituting: ['teaching' 'research' 'international']\n",
      "['teaching']\n",
      "Substituting 2: ['teaching']\n",
      "Possible configs:\n",
      "[international     True\n",
      "income           False\n",
      "teaching         False\n",
      "citations         True\n",
      "research          True\n",
      "Name: 2, dtype: bool, international     True\n",
      "income           False\n",
      "teaching          True\n",
      "citations         True\n",
      "research         False\n",
      "Name: 2, dtype: bool, international    False\n",
      "income           False\n",
      "teaching          True\n",
      "citations         True\n",
      "research          True\n",
      "Name: 2, dtype: bool]\n",
      "international     True\n",
      "income           False\n",
      "teaching         False\n",
      "citations         True\n",
      "research          True\n",
      "Name: 2, dtype: bool\n",
      "[('research', -2.801417), ('international', -2.801417)]\n",
      "Substituting: ['teaching' 'research' 'international']\n",
      "['teaching']\n",
      "Substituting 2: ['teaching']\n",
      "Substituting: ['teaching' 'research' 'international']\n",
      "['teaching']\n",
      "Substituting 2: ['teaching']\n",
      "Possible configs:\n",
      "[international     True\n",
      "income           False\n",
      "teaching         False\n",
      "citations         True\n",
      "research          True\n",
      "Name: 2, dtype: bool, international     True\n",
      "income           False\n",
      "teaching          True\n",
      "citations         True\n",
      "research         False\n",
      "Name: 2, dtype: bool, international    False\n",
      "income           False\n",
      "teaching          True\n",
      "citations         True\n",
      "research          True\n",
      "Name: 2, dtype: bool]\n",
      "Checking\n",
      "['international' 'citations' 'research']\n",
      "['international' 'citations' 'research']\n",
      "Checking\n",
      "['international' 'citations' 'research']\n",
      "['international' 'teaching' 'citations']\n",
      "Checking\n",
      "['international' 'citations' 'research']\n",
      "['teaching' 'citations' 'research']\n",
      "Checking\n",
      "['international' 'teaching' 'citations']\n",
      "['international' 'citations' 'research']\n",
      "Checking\n",
      "['international' 'teaching' 'citations']\n",
      "['international' 'teaching' 'citations']\n",
      "Checking\n",
      "['international' 'teaching' 'citations']\n",
      "['teaching' 'citations' 'research']\n",
      "Checking\n",
      "['teaching' 'citations' 'research']\n",
      "['international' 'citations' 'research']\n",
      "Checking\n",
      "['teaching' 'citations' 'research']\n",
      "['international' 'teaching' 'citations']\n",
      "Checking\n",
      "['teaching' 'citations' 'research']\n",
      "['teaching' 'citations' 'research']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/state/partition1/job-51014997/ipykernel_2058621/3708206883.py:31: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  cumulative_cont = np.cumsum(np.abs(row_cont)[order]) / total_contribution\n",
      "/state/partition1/job-51014997/ipykernel_2058621/3708206883.py:34: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  mask = (cumulative_cont < 1 - threshold)[order]\n",
      "/state/partition1/job-51014997/ipykernel_2058621/3708206883.py:31: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  cumulative_cont = np.cumsum(np.abs(row_cont)[order]) / total_contribution\n",
      "/state/partition1/job-51014997/ipykernel_2058621/3708206883.py:34: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  mask = (cumulative_cont < 1 - threshold)[order]\n",
      "/state/partition1/job-51014997/ipykernel_2058621/3708206883.py:31: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  cumulative_cont = np.cumsum(np.abs(row_cont)[order]) / total_contribution\n",
      "/state/partition1/job-51014997/ipykernel_2058621/3708206883.py:34: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  mask = (cumulative_cont < 1 - threshold)[order]\n",
      "/state/partition1/job-51014997/ipykernel_2058621/3708206883.py:31: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  cumulative_cont = np.cumsum(np.abs(row_cont)[order]) / total_contribution\n",
      "/state/partition1/job-51014997/ipykernel_2058621/3708206883.py:34: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  mask = (cumulative_cont < 1 - threshold)[order]\n",
      "/state/partition1/job-51014997/ipykernel_2058621/3708206883.py:31: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  cumulative_cont = np.cumsum(np.abs(row_cont)[order]) / total_contribution\n",
      "/state/partition1/job-51014997/ipykernel_2058621/3708206883.py:34: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  mask = (cumulative_cont < 1 - threshold)[order]\n",
      "/state/partition1/job-51014997/ipykernel_2058621/3708206883.py:31: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  cumulative_cont = np.cumsum(np.abs(row_cont)[order]) / total_contribution\n",
      "/state/partition1/job-51014997/ipykernel_2058621/3708206883.py:34: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  mask = (cumulative_cont < 1 - threshold)[order]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0    1.000000\n",
       "1    0.333333\n",
       "2    0.500000\n",
       "dtype: float64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = [[-0.428721,-2.801417,6.815626,-0.092408,-1.213119], [-0.428721,-2.801417,6.815626,-0.092408,-2.801417],\n",
    "     [-2.801417,-2.801417,6.815626,-0.092408,-2.801417]]\n",
    "\n",
    "b = [[-0.714536,-4.669028,11.359376,-0.154013,-2.021865], [-0.428721,-2.801417,6.815626,-0.092408,-2.801417],\n",
    "     [-2.801417,-2.801417,6.815626,-0.092408,-2.801417]]\n",
    "\n",
    "columns=['teaching', 'research', 'citations', 'income', 'international']\n",
    "\n",
    "jaccard_agreement(pd.DataFrame(a, columns=columns), pd.DataFrame(b, columns=columns), n_features=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfa25be2-5119-4590-905e-a6e1f1b2f336",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2b00049-7c55-48b8-98a0-101066111c8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "benchmark",
   "language": "python",
   "name": "benchmark"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
