{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(\"..\")\n",
    "\n",
    "import tqdm\n",
    "import time\n",
    "from copy import deepcopy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.utils import check_random_state\n",
    "from lightgbm import LGBMRanker\n",
    "from sharp import ShaRP\n",
    "from sharp.utils import scores_to_ordering\n",
    "from xai_ranking.preprocessing import preprocess_higher_education_data\n",
    "from xai_ranking.scorers import higher_education_score\n",
    "from mlresearch.utils import check_random_states\n",
    "\n",
    "from xai_ranking.preprocessing import (\n",
    "    preprocess_atp_data,\n",
    "    preprocess_csrank_data,\n",
    "    preprocess_higher_education_data,\n",
    "    preprocess_movers_data,\n",
    "    preprocess_synthetic_data,\n",
    ")\n",
    "from xai_ranking.datasets import (\n",
    "    fetch_atp_data,\n",
    "    fetch_csrank_data,\n",
    "    fetch_higher_education_data,\n",
    "    fetch_movers_data,\n",
    "    fetch_synthetic_data,\n",
    ")\n",
    "from xai_ranking.scorers import (\n",
    "    atp_score,\n",
    "    csrank_score,\n",
    "    higher_education_score,\n",
    "    synthetic_equal_score_3ftrs,\n",
    ")\n",
    "from xai_ranking.metrics import (\n",
    "    explanation_sensitivity,\n",
    "    outcome_sensitivity,\n",
    "    bootstrapped_explanation_consistency,\n",
    "    cross_method_explanation_consistency,\n",
    "    cross_method_outcome_consistency,\n",
    "    outcome_fidelity,\n",
    ")\n",
    "\n",
    "RNG_SEED = 42\n",
    "N_RUNS = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22c5f17f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up ranker for the moving company dataset:\n",
    "X, ranks, score = preprocess_movers_data(fetch_movers_data(test=False))\n",
    "qids_train = X.index.value_counts().to_numpy()\n",
    "\n",
    "model = LGBMRanker(\n",
    "    objective=\"lambdarank\", label_gain=list(range(max(ranks) + 1)), verbose=-1\n",
    ")\n",
    "model.fit(\n",
    "    X=X,\n",
    "    y=ranks,\n",
    "    group=qids_train,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0fdea795afd09c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "random_states = check_random_states(RNG_SEED, N_RUNS)\n",
    "\n",
    "datasets = [\n",
    "    {\n",
    "        \"name\": \"Higher Education\",\n",
    "        \"data\": preprocess_higher_education_data(\n",
    "            fetch_higher_education_data(year=2020)\n",
    "        ),\n",
    "        \"scorer\": higher_education_score,\n",
    "        \"n_observations\": 100,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"ATP\",\n",
    "        \"data\": preprocess_atp_data(fetch_atp_data()),\n",
    "        \"scorer\": atp_score,\n",
    "        \"n_observations\": 86,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"CSRank\",\n",
    "        \"data\": preprocess_csrank_data(fetch_csrank_data()),\n",
    "        \"scorer\": csrank_score,\n",
    "        \"n_observations\": 100,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Moving Company\",\n",
    "        \"data\": preprocess_movers_data(fetch_movers_data(test=True)),\n",
    "        \"scorer\": model.predict,\n",
    "        \"n_observations\": 100,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Synthetic_0\",\n",
    "        \"data\": preprocess_synthetic_data(\n",
    "            fetch_synthetic_data(synth_dt_version=0, item_num=2000)\n",
    "        ),\n",
    "        \"scorer\": synthetic_equal_score_3ftrs,\n",
    "        \"n_observations\": 100,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Synthetic_1\",\n",
    "        \"data\": preprocess_synthetic_data(\n",
    "            fetch_synthetic_data(synth_dt_version=1, item_num=2000)\n",
    "        ),\n",
    "        \"scorer\": synthetic_equal_score_3ftrs,\n",
    "        \"n_observations\": 100,\n",
    "    },\n",
    "    {\n",
    "        \"name\": \"Synthetic_2\",\n",
    "        \"data\": preprocess_synthetic_data(\n",
    "            fetch_synthetic_data(synth_dt_version=2, item_num=2000)\n",
    "        ),\n",
    "        \"scorer\": synthetic_equal_score_3ftrs,\n",
    "        \"n_observations\": 100,\n",
    "    },\n",
    "]\n",
    "\n",
    "approaches = [\"rank\", \"rank_score\", \"pairwise\"]\n",
    "\n",
    "default_kwargs = {\n",
    "    \"measure\": \"shapley\",\n",
    "    \"sample_size\": None,\n",
    "    \"coalition_size\": None,\n",
    "    \"replace\": False,\n",
    "    \"n_jobs\": 12,\n",
    "}\n",
    "parameters_to_change = {\n",
    "    \"coalition_size\": [i for i in range(1, 7)],\n",
    "    \"sample_size\": [20, 50, 100, 250] + list(range(500, 2000, 500)),\n",
    "    \"n_jobs\": [1, 2, 4, 8, 16, 32, 48],\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ce44d4e8b8ec501",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Super janky code... It would be a good exercise to refactor this\n",
    "\n",
    "result_cols = (\n",
    "    [\n",
    "        \"dataset\",\n",
    "        \"n_observations\",\n",
    "        \"approach\",\n",
    "        \"parameter\",\n",
    "        \"parameter_value\",\n",
    "        \"avg_time\",\n",
    "    ]\n",
    "    + [f\"time_{i}\" for i in range(N_RUNS)]\n",
    "    + [f\"agreement_kendall_{i}\" for i in range(N_RUNS)]\n",
    "    + [f\"agreement_jaccard2_{i}\" for i in range(N_RUNS)]\n",
    "    + [f\"agreement_euclidean_{i}\" for i in range(N_RUNS)]\n",
    "    + [f\"fidelity_{i}\" for i in range(N_RUNS)]\n",
    ")\n",
    "\n",
    "\n",
    "for dataset in datasets:\n",
    "\n",
    "    result_df = []\n",
    "    # Set up basic settings\n",
    "    X = dataset[\"data\"][0]\n",
    "    scorer = dataset[\"scorer\"]\n",
    "    scores = np.array(scorer(dataset[\"data\"][0]))\n",
    "    ranking = scores_to_ordering(scores)\n",
    "\n",
    "    rng = check_random_state(RNG_SEED)\n",
    "    sam_idx1 = rng.choice(\n",
    "        np.indices((X.shape[0],)).squeeze(),\n",
    "        size=dataset[\"n_observations\"],\n",
    "        replace=False,\n",
    "    )\n",
    "    sam_idx2 = rng.choice(\n",
    "        np.indices((X.shape[0],)).squeeze(),\n",
    "        size=dataset[\"n_observations\"],\n",
    "        replace=False,\n",
    "    )\n",
    "\n",
    "    for approach in approaches:\n",
    "        print(\"----------------\", dataset[\"name\"], \"|\", approach, \"----------------\")\n",
    "\n",
    "        times = []\n",
    "        kendall_cons = []\n",
    "        jaccard_cons = []\n",
    "        euclidean_cons = []\n",
    "        fidelity = []\n",
    "\n",
    "        print(\"Exact computation\")\n",
    "        for i in tqdm.tqdm(range(N_RUNS)):\n",
    "            start = time.time()\n",
    "            if approach != \"pairwise\":\n",
    "                baseline_sharp = ShaRP(\n",
    "                    qoi=approach,\n",
    "                    target_function=dataset[\"scorer\"],\n",
    "                    random_state=random_states[i],\n",
    "                    **default_kwargs,\n",
    "                )\n",
    "                baseline_sharp.fit(X)\n",
    "                baseline_contr = baseline_sharp.all(X.values[sam_idx1])\n",
    "            else:\n",
    "                baseline_sharp = ShaRP(\n",
    "                    qoi=\"rank\",\n",
    "                    target_function=dataset[\"scorer\"],\n",
    "                    random_state=random_states[i],\n",
    "                    **default_kwargs,\n",
    "                )\n",
    "                baseline_sharp.fit(X)\n",
    "                baseline_pairwise = []\n",
    "                for idx1, idx2 in zip(sam_idx1, sam_idx2):\n",
    "                    baseline_pairwise.append(\n",
    "                        baseline_sharp.pairwise(X.values[idx1], X.values[idx2])\n",
    "                    )\n",
    "                baseline_contr = np.array(baseline_pairwise)\n",
    "\n",
    "            end = time.time()\n",
    "\n",
    "            baseline_contr = pd.DataFrame(\n",
    "                baseline_contr, columns=X.columns, index=X.index.values[sam_idx1]\n",
    "            )\n",
    "            # Save metrics\n",
    "            times.append(end - start)\n",
    "            kendall_cons.append(np.nan)\n",
    "            jaccard_cons.append(np.nan)\n",
    "            euclidean_cons.append(np.nan)\n",
    "\n",
    "            target = scores if approach == \"rank_score\" else ranking\n",
    "            avg_target = target.mean()\n",
    "            if approach != \"pairwise\":\n",
    "                res_ = outcome_fidelity(\n",
    "                    baseline_contr,\n",
    "                    target[sam_idx1],\n",
    "                    avg_target,\n",
    "                    target_max=X.shape[0] if approach == \"rank\" else target.max(),\n",
    "                    rank=approach == \"rank\",\n",
    "                )\n",
    "            else:\n",
    "                res_ = outcome_fidelity(\n",
    "                    baseline_contr,\n",
    "                    target[sam_idx1],\n",
    "                    avg_target,\n",
    "                    target_max=X.shape[0] if approach == \"rank\" else target.max(),\n",
    "                    target_pairs=target[sam_idx2],\n",
    "                    rank=approach == \"rank\",\n",
    "                )\n",
    "\n",
    "            fidelity.append(res_)\n",
    "\n",
    "        exact_results_row = (\n",
    "            [\n",
    "                dataset[\"name\"],\n",
    "                dataset[\"n_observations\"],\n",
    "                approach,\n",
    "                np.nan,\n",
    "                np.nan,\n",
    "                np.mean(times),\n",
    "            ]\n",
    "            + times\n",
    "            + kendall_cons\n",
    "            + jaccard_cons\n",
    "            + euclidean_cons\n",
    "            + fidelity\n",
    "        )\n",
    "        result_df.append(exact_results_row)\n",
    "        print(\"Finished computing exact results\")\n",
    "        ############################################################################################\n",
    "\n",
    "        for parameter, parameter_values in parameters_to_change.items():\n",
    "            print(f\"Alternating parameter: {parameter}\")\n",
    "            default_value = deepcopy(\n",
    "                default_kwargs[parameter] if parameter in default_kwargs else None\n",
    "            )\n",
    "\n",
    "            if parameter == \"coalition_size\":\n",
    "                parameter_values = [\n",
    "                    val for val in parameter_values if X.shape[-1] > val\n",
    "                ] + [X.shape[-1]]\n",
    "            if parameter == \"sample_size\":\n",
    "                parameter_values = [\n",
    "                    val for val in parameter_values if X.shape[0] >= val\n",
    "                ] + [X.shape[0]]\n",
    "\n",
    "            for parameter_value in tqdm.tqdm(parameter_values):\n",
    "\n",
    "                default_kwargs[parameter] = parameter_value\n",
    "\n",
    "                times = []\n",
    "                kendall_cons = []\n",
    "                jaccard_cons = []\n",
    "                euclidean_cons = []\n",
    "                fidelity = []\n",
    "\n",
    "                print(f\"Parameter {parameter}, value {parameter_value}\")\n",
    "                for i in tqdm.tqdm(range(N_RUNS)):\n",
    "                    start = time.time()\n",
    "                    if approach != \"pairwise\":\n",
    "                        sharp = ShaRP(\n",
    "                            qoi=approach,\n",
    "                            target_function=dataset[\"scorer\"],\n",
    "                            random_state=random_states[i],\n",
    "                            **default_kwargs,\n",
    "                        )\n",
    "                        sharp.fit(X)\n",
    "                        contr = sharp.all(X.values[sam_idx1])\n",
    "                    else:\n",
    "                        sharp = ShaRP(\n",
    "                            qoi=\"rank\",\n",
    "                            target_function=dataset[\"scorer\"],\n",
    "                            random_state=random_states[i],\n",
    "                            **default_kwargs,\n",
    "                        )\n",
    "                        sharp.fit(X)\n",
    "                        pairwise = []\n",
    "                        for idx1, idx2 in zip(sam_idx1, sam_idx2):\n",
    "                            pairwise.append(\n",
    "                                sharp.pairwise(X.values[idx1], X.values[idx2])\n",
    "                            )\n",
    "                        contr = np.array(pairwise)\n",
    "\n",
    "                    end = time.time()\n",
    "\n",
    "                    contr = pd.DataFrame(\n",
    "                        contr, columns=X.columns, index=np.array(X.index)[sam_idx1]\n",
    "                    )\n",
    "\n",
    "                    # Save metrics\n",
    "                    times.append(end - start)\n",
    "                    kendall_cons.append(\n",
    "                        cross_method_explanation_consistency(\n",
    "                            contr, baseline_contr, measure=\"kendall\"\n",
    "                        )[0]\n",
    "                    )\n",
    "                    jaccard_cons.append(\n",
    "                        cross_method_explanation_consistency(\n",
    "                            contr, baseline_contr, measure=\"jaccard\", n_features=2\n",
    "                        )[0]\n",
    "                    )\n",
    "                    euclidean_cons.append(\n",
    "                        cross_method_explanation_consistency(\n",
    "                            contr, baseline_contr, measure=\"euclidean\"\n",
    "                        )[0]\n",
    "                    )\n",
    "                    target = scores if approach == \"rank_score\" else ranking\n",
    "                    avg_target = target.mean()\n",
    "                    res_ = outcome_fidelity(\n",
    "                        contr,\n",
    "                        target[sam_idx1],\n",
    "                        avg_target,\n",
    "                        target_max=X.shape[0] if approach == \"rank\" else target.max(),\n",
    "                        target_pairs=target[sam_idx2],\n",
    "                        rank=approach == \"rank\",\n",
    "                    )\n",
    "\n",
    "                    fidelity.append(res_)\n",
    "\n",
    "                results_row = (\n",
    "                    [\n",
    "                        dataset[\"name\"],\n",
    "                        dataset[\"n_observations\"],\n",
    "                        approach,\n",
    "                        parameter,\n",
    "                        parameter_value,\n",
    "                        np.mean(times),\n",
    "                    ]\n",
    "                    + times\n",
    "                    + kendall_cons\n",
    "                    + jaccard_cons\n",
    "                    + euclidean_cons\n",
    "                    + fidelity\n",
    "                )\n",
    "                result_df.append(results_row)\n",
    "                print(f\"Stored results for {parameter} | {parameter_value}\")\n",
    "\n",
    "            default_kwargs[parameter] = default_value\n",
    "\n",
    "    results = pd.DataFrame(result_df, columns=result_cols)\n",
    "    results.to_csv(\"results/time-experiment-\" + dataset[\"name\"] + \".csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac3fa04b178aeec3",
   "metadata": {},
   "outputs": [],
   "source": [
    "results = pd.DataFrame(result_df, columns=result_cols)\n",
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff441073",
   "metadata": {},
   "outputs": [],
   "source": [
    "metric = \"exp_cons_kendall\"\n",
    "col_mask = results.columns.str.startswith(metric)\n",
    "results[f\"avg_{metric}\"] = results.iloc[:, col_mask].mean(1)\n",
    "col_mask = results.columns == f\"avg_{metric}\"\n",
    "col_mask[:6] = True\n",
    "results.iloc[:, col_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04be276a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "sharp",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
